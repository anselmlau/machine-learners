{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', header=0, encoding='iso-8859-1')\n",
    "df_test = pd.read_csv('test.csv', header=0, encoding='iso-8859-1')\n",
    "df_att = pd.read_csv('attributes.csv', header=0, encoding='iso-8859-1')\n",
    "df_des = pd.read_csv('product_descriptions.csv', header=0, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num of search term distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_term_analysis(df, comment):\n",
    "    search_terms = [search_term.split() for search_term in df.search_term]\n",
    "    num_words_used = [len(search_term) for search_term in search_terms]\n",
    "    avg_terms_used = sum(num_words_used) / float(len(search_terms))\n",
    "    print 'num_words_used: {}'.format(Counter(num_words_used))\n",
    "    print 'avg_terms_used: {}'.format(avg_terms_used)\n",
    "    \n",
    "    return search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words_used: Counter({3: 26575, 2: 18386, 4: 14847, 5: 6601, 1: 4503, 6: 2076, 7: 741, 8: 204, 9: 80, 11: 31, 10: 10, 12: 9, 14: 4})\n",
      "avg_terms_used: 3.15920720429\n"
     ]
    }
   ],
   "source": [
    "df_train.head()\n",
    "df_train.describe()\n",
    "search_terms_train = search_term_analysis(df_train, 'Training Data...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words_used: Counter({3: 56420, 2: 51329, 4: 28100, 1: 12772, 5: 12004, 6: 4004, 7: 1241, 8: 469, 9: 145, 10: 104, 12: 54, 11: 46, 14: 4, 13: 1})\n",
      "avg_terms_used: 2.98237478478\n"
     ]
    }
   ],
   "source": [
    "df_test.head()\n",
    "search_terms_test = search_term_analysis(df_test, 'Training Data...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Num of unique products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data - num of records: 74067, num unique products: 54667\n",
      "testing data - num of records: 166693, num unique products: 97460\n"
     ]
    }
   ],
   "source": [
    "print 'training data - num of records: {0}, num unique products: {1}'.format(len(df_train), len(set(df_train.product_uid)))\n",
    "print 'testing data - num of records: {0}, num unique products: {1}'.format(len(df_test), len(set(df_test.product_uid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by num of search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'microwaves'],\n",
       " [u'disposer'],\n",
       " [u'bamboo'],\n",
       " [u'grayson'],\n",
       " [u'post'],\n",
       " [u'outdoorfurniture'],\n",
       " [u'wiremesh'],\n",
       " [u'post'],\n",
       " [u'4x6'],\n",
       " [u'melnor'],\n",
       " [u'deckpaint'],\n",
       " [u'silicone'],\n",
       " [u'chipper'],\n",
       " [u'bidet'],\n",
       " [u'slatwall'],\n",
       " [u'respirator'],\n",
       " [u'lamp'],\n",
       " [u'Lawnmowers'],\n",
       " [u'closetmade'],\n",
       " [u'closetmaid'],\n",
       " [u'post'],\n",
       " [u'omnifilter'],\n",
       " [u'colosso'],\n",
       " [u'respirator'],\n",
       " [u'miricale'],\n",
       " [u'sheetrock'],\n",
       " [u'bathrooms'],\n",
       " [u'bootz'],\n",
       " [u'porcelain'],\n",
       " [u'aspiradora'],\n",
       " [u'shredder'],\n",
       " [u'chipper'],\n",
       " [u'Fuses'],\n",
       " [u'home-flex'],\n",
       " [u'knob'],\n",
       " [u'Lawnmowers'],\n",
       " [u'hindges'],\n",
       " [u'lathe'],\n",
       " [u'roller'],\n",
       " [u'clab'],\n",
       " [u'chaise'],\n",
       " [u'tent'],\n",
       " [u'cieling'],\n",
       " [u'gates'],\n",
       " [u'ceadar'],\n",
       " [u'pruners'],\n",
       " [u'barreir'],\n",
       " [u'water'],\n",
       " [u'azek'],\n",
       " [u'azek'],\n",
       " [u'closetmaid'],\n",
       " [u'stringer'],\n",
       " [u'thermoclear'],\n",
       " [u'stakes'],\n",
       " [u'slatwall'],\n",
       " [u'roller'],\n",
       " [u'slatwall'],\n",
       " [u'roller'],\n",
       " [u'huskvarna'],\n",
       " [u'post'],\n",
       " [u'plywoods'],\n",
       " [u'artificial'],\n",
       " [u'canopy'],\n",
       " [u'awnings'],\n",
       " [u'frp'],\n",
       " [u'rounds'],\n",
       " [u'round'],\n",
       " [u'rounds'],\n",
       " [u'closetmaid'],\n",
       " [u'sinks'],\n",
       " [u'roundup'],\n",
       " [u'sheetrock'],\n",
       " [u'spreader'],\n",
       " [u'tow'],\n",
       " [u'spreader'],\n",
       " [u'Lawnmowers'],\n",
       " [u'lamp'],\n",
       " [u'bathrooms'],\n",
       " [u'frp'],\n",
       " [u'tubs'],\n",
       " [u'briton'],\n",
       " [u'venner'],\n",
       " [u'barreir'],\n",
       " [u'durock'],\n",
       " [u'briton'],\n",
       " [u'spreader'],\n",
       " [u'lanterun'],\n",
       " [u'Fuses'],\n",
       " [u'tank'],\n",
       " [u'tent'],\n",
       " [u'roundup'],\n",
       " [u'stovetop'],\n",
       " [u'glasses'],\n",
       " [u'credenza'],\n",
       " [u'Fuses'],\n",
       " [u'tubs'],\n",
       " [u'rounds'],\n",
       " [u'roundup'],\n",
       " [u'waterton'],\n",
       " [u'cieling'],\n",
       " [u'brushless'],\n",
       " [u'paracord'],\n",
       " [u'paracord'],\n",
       " [u'doorbell'],\n",
       " [u'mtd'],\n",
       " [u'sinks'],\n",
       " [u'banbury'],\n",
       " [u'itwinkle'],\n",
       " [u'bidet'],\n",
       " [u'respirator'],\n",
       " [u'bateries'],\n",
       " [u'lockset'],\n",
       " [u'cieling'],\n",
       " [u'table'],\n",
       " [u'gates'],\n",
       " [u'doorbell'],\n",
       " [u'edsel'],\n",
       " [u'closetmaid'],\n",
       " [u'platforms'],\n",
       " [u'scaffoldings'],\n",
       " [u'spreader'],\n",
       " [u'construction'],\n",
       " [u'gates'],\n",
       " [u'pulley'],\n",
       " [u'hagchet'],\n",
       " [u'coveralls'],\n",
       " [u'labo'],\n",
       " [u'backsplach'],\n",
       " [u'standoffs'],\n",
       " [u'blowers'],\n",
       " [u'Lawnmowers'],\n",
       " [u'ion'],\n",
       " [u'closetmaid'],\n",
       " [u'lockset'],\n",
       " [u'spreader'],\n",
       " [u'melnor'],\n",
       " [u'blowers'],\n",
       " [u'makita'],\n",
       " [u'echo'],\n",
       " [u'chipper'],\n",
       " [u'standoffs'],\n",
       " [u'scaffolding'],\n",
       " [u'gates'],\n",
       " [u'microwaves'],\n",
       " [u'chairs'],\n",
       " [u'mdog'],\n",
       " [u'sheetrock'],\n",
       " [u'pulley'],\n",
       " [u'plywoods'],\n",
       " [u'echo'],\n",
       " [u'canopy'],\n",
       " [u'car'],\n",
       " [u'chime'],\n",
       " [u'ashwood'],\n",
       " [u'scod'],\n",
       " [u'lamp'],\n",
       " [u'mdog'],\n",
       " [u'microwaves'],\n",
       " [u'scaffolding'],\n",
       " [u'scaffoldings'],\n",
       " [u'scaffolds'],\n",
       " [u'weed'],\n",
       " [u'pruners'],\n",
       " [u'microwaves'],\n",
       " [u'marine'],\n",
       " [u'lathe'],\n",
       " [u'Fuses'],\n",
       " [u'forimca'],\n",
       " [u'outdoorfurniture'],\n",
       " [u'acrylic'],\n",
       " [u'slatwall'],\n",
       " [u'handtools'],\n",
       " [u'wheelbarow'],\n",
       " [u'wheelbarrows'],\n",
       " [u'echo'],\n",
       " [u'didger'],\n",
       " [u'quick'],\n",
       " [u'chairs'],\n",
       " [u'4x6'],\n",
       " [u'closetmaid'],\n",
       " [u'steqamers'],\n",
       " [u'azek'],\n",
       " [u'melnor'],\n",
       " [u'insallation'],\n",
       " [u'insullation'],\n",
       " [u'post'],\n",
       " [u'acrylic'],\n",
       " [u'desks'],\n",
       " [u'sjhelf'],\n",
       " [u'hecurles'],\n",
       " [u'tent'],\n",
       " [u'table'],\n",
       " [u'karcher'],\n",
       " [u'closetmade'],\n",
       " [u'closetmaid'],\n",
       " [u'1x8x8'],\n",
       " [u'drils'],\n",
       " [u'water'],\n",
       " [u'frp'],\n",
       " [u'wa'],\n",
       " [u'bended'],\n",
       " [u'Lawnmowers'],\n",
       " [u'cieling'],\n",
       " [u'ion'],\n",
       " [u'water'],\n",
       " [u'doorbell'],\n",
       " [u'scod'],\n",
       " [u'sheetrock'],\n",
       " [u'sauder'],\n",
       " [u'owens'],\n",
       " [u'acrylic'],\n",
       " [u'thermoclear'],\n",
       " [u'chisel'],\n",
       " [u'barreir'],\n",
       " [u'slatwall'],\n",
       " [u'chaise'],\n",
       " [u'chime'],\n",
       " [u'table'],\n",
       " [u'microwaves'],\n",
       " [u'4x6'],\n",
       " [u'post'],\n",
       " [u'paracord'],\n",
       " [u'tubs'],\n",
       " [u'table'],\n",
       " [u'tank'],\n",
       " [u'makita'],\n",
       " [u'lathe'],\n",
       " [u'echo'],\n",
       " [u'slatwall'],\n",
       " [u'scaffolding'],\n",
       " [u'insullation'],\n",
       " [u'owens'],\n",
       " [u'bolens'],\n",
       " [u'paintbrushes'],\n",
       " [u'4x6'],\n",
       " [u'azek'],\n",
       " [u'silicone'],\n",
       " [u'1x8x8'],\n",
       " [u'1x12x10'],\n",
       " [u'fountains'],\n",
       " [u'keg'],\n",
       " [u'pulley'],\n",
       " [u'echo'],\n",
       " [u'weed'],\n",
       " [u'microwaves'],\n",
       " [u'rumbl;estone'],\n",
       " [u'tar'],\n",
       " [u'paracord'],\n",
       " [u'lathe'],\n",
       " [u'insullation'],\n",
       " [u'melnor'],\n",
       " [u'frp'],\n",
       " [u'sheetrock'],\n",
       " [u'unsulation'],\n",
       " [u'upholstry'],\n",
       " [u'stakes'],\n",
       " [u'canopy'],\n",
       " [u'thermoplastic'],\n",
       " [u'chandeliers'],\n",
       " [u'gates'],\n",
       " [u'stringer'],\n",
       " [u'scaffolding'],\n",
       " [u'scaffolds'],\n",
       " [u'chime'],\n",
       " [u'acrylic'],\n",
       " [u'polycarbonite'],\n",
       " [u'table'],\n",
       " [u'tan'],\n",
       " [u'paracord'],\n",
       " [u'ion'],\n",
       " [u'taladros'],\n",
       " [u'azek'],\n",
       " [u'canopy'],\n",
       " [u'desks'],\n",
       " [u'Lawnmowers'],\n",
       " [u'knob'],\n",
       " [u'nobs'],\n",
       " [u'desks'],\n",
       " [u'chime'],\n",
       " [u'doorbell'],\n",
       " [u'echo'],\n",
       " [u'gas'],\n",
       " [u'chairs'],\n",
       " [u'Lawnmowers'],\n",
       " [u'microwaves'],\n",
       " [u'banbury'],\n",
       " [u'shopac'],\n",
       " [u'fountains'],\n",
       " [u'acrylic'],\n",
       " [u'silicone'],\n",
       " [u'acrylic'],\n",
       " [u'polycarbonite'],\n",
       " [u'parch'],\n",
       " [u'echo'],\n",
       " [u'pulley'],\n",
       " [u'shoplight'],\n",
       " [u'roundup'],\n",
       " [u'zeroturn'],\n",
       " [u'milwaukie'],\n",
       " [u'r-30'],\n",
       " [u'table'],\n",
       " [u'marine'],\n",
       " [u'blowers'],\n",
       " [u'fountains'],\n",
       " [u'technisoil'],\n",
       " [u'roundup'],\n",
       " [u'doorbell'],\n",
       " [u'frp'],\n",
       " [u'stakes'],\n",
       " [u'acrylic'],\n",
       " [u'polycarbonite'],\n",
       " [u'wet/dry'],\n",
       " [u'lanterun'],\n",
       " [u'bidet'],\n",
       " [u'chandeliers'],\n",
       " [u'roundup'],\n",
       " [u'respirator'],\n",
       " [u'chairs'],\n",
       " [u'lockset'],\n",
       " [u'Fuses'],\n",
       " [u'awnings'],\n",
       " [u'koolaroo'],\n",
       " [u'lamp'],\n",
       " [u'uplihght'],\n",
       " [u'table'],\n",
       " [u'echo'],\n",
       " [u'chipper'],\n",
       " [u'chisel'],\n",
       " [u'edsel'],\n",
       " [u'4x6'],\n",
       " [u'makita'],\n",
       " [u'awnings'],\n",
       " [u'slatwall'],\n",
       " [u'durock'],\n",
       " [u'respirator'],\n",
       " [u'paracord'],\n",
       " [u'karcher'],\n",
       " [u'roller'],\n",
       " [u'frp'],\n",
       " [u'coveralls'],\n",
       " [u'fountains'],\n",
       " [u'xps'],\n",
       " [u'stakes'],\n",
       " [u'bamboo'],\n",
       " [u'prices'],\n",
       " [u'post'],\n",
       " [u'chipper'],\n",
       " [u'acrylic'],\n",
       " [u'florida'],\n",
       " [u'hagchet'],\n",
       " [u'coveralls'],\n",
       " [u'taladros'],\n",
       " [u'4x6'],\n",
       " [u'Fuses'],\n",
       " [u'echo'],\n",
       " [u'sheetrock'],\n",
       " [u'bamboo'],\n",
       " [u'stakes'],\n",
       " [u'4x6'],\n",
       " [u'scaffolding'],\n",
       " [u'tresers'],\n",
       " [u'sheetrock'],\n",
       " [u'acrylic'],\n",
       " [u'extractor'],\n",
       " [u'silverton'],\n",
       " [u'durock'],\n",
       " [u'acrylic'],\n",
       " [u'drils'],\n",
       " [u'makita'],\n",
       " [u'lockset'],\n",
       " [u'step'],\n",
       " [u'chairs'],\n",
       " [u'closetmade'],\n",
       " [u'closetmaid'],\n",
       " [u'roundup'],\n",
       " [u'To'],\n",
       " [u'sinks'],\n",
       " [u'table'],\n",
       " [u'bamboo'],\n",
       " [u'spreader'],\n",
       " [u'melnor'],\n",
       " [u'lathe'],\n",
       " [u'closetmade'],\n",
       " [u'forimca'],\n",
       " [u'wiremesh'],\n",
       " [u'wheelbarow'],\n",
       " [u'platforms'],\n",
       " [u'awnings'],\n",
       " [u'insullation'],\n",
       " [u'azek'],\n",
       " [u'lockset'],\n",
       " [u'MASKING'],\n",
       " [u'bidet'],\n",
       " [u'1x8x8'],\n",
       " [u'fountains'],\n",
       " [u'sinks'],\n",
       " [u'rebarbender'],\n",
       " [u'table'],\n",
       " [u'chairs'],\n",
       " [u'stakes'],\n",
       " [u'plywoods'],\n",
       " [u'lockset'],\n",
       " [u'chairs'],\n",
       " [u'credenza'],\n",
       " [u'zeroturn'],\n",
       " [u'acrylic'],\n",
       " [u'silicone'],\n",
       " [u'roundup'],\n",
       " [u'tent'],\n",
       " [u'lamp'],\n",
       " [u'lockset'],\n",
       " [u'silicone'],\n",
       " [u'insallation'],\n",
       " [u'owens'],\n",
       " [u'storeage'],\n",
       " [u'lathe'],\n",
       " [u'tar'],\n",
       " [u'brushless'],\n",
       " [u'hagchet'],\n",
       " [u'chandeliers'],\n",
       " [u'lamp'],\n",
       " [u'winterizer'],\n",
       " [u'sheetrock'],\n",
       " [u'tubs'],\n",
       " [u'chime'],\n",
       " [u'roundup'],\n",
       " [u'makita'],\n",
       " [u'pulley'],\n",
       " [u'r-30'],\n",
       " [u'frp'],\n",
       " [u'acrylic'],\n",
       " [u'spreader'],\n",
       " [u'bamboo'],\n",
       " [u'banbury'],\n",
       " [u'forimca'],\n",
       " [u'laminated'],\n",
       " [u'post'],\n",
       " [u'chipper'],\n",
       " [u'mdog'],\n",
       " [u'roller'],\n",
       " [u'echo'],\n",
       " [u'rumbl;estone'],\n",
       " [u'chandeliers'],\n",
       " [u'workforce'],\n",
       " [u'canyon'],\n",
       " [u'durock'],\n",
       " [u'venner'],\n",
       " [u'versa'],\n",
       " [u'byefold'],\n",
       " [u'replacement'],\n",
       " [u'table'],\n",
       " [u'4x6'],\n",
       " [u'makita'],\n",
       " [u'gates'],\n",
       " [u'tent'],\n",
       " [u'Fuses'],\n",
       " [u'saud'],\n",
       " [u'gates'],\n",
       " [u'durock'],\n",
       " [u'tubs'],\n",
       " [u'lathe'],\n",
       " [u'Buff'],\n",
       " [u'fountains'],\n",
       " [u'chisel'],\n",
       " [u'bathrooms'],\n",
       " [u'slatwall'],\n",
       " [u'closetmaid'],\n",
       " [u'tent'],\n",
       " [u'scaffolding'],\n",
       " [u'awnings'],\n",
       " [u'bathrooms'],\n",
       " [u'shopac'],\n",
       " [u'chisel'],\n",
       " [u'closetmaid'],\n",
       " [u'bidet'],\n",
       " [u'doorbell'],\n",
       " [u'steqamers'],\n",
       " [u'beach'],\n",
       " [u'tubs'],\n",
       " [u'sinks'],\n",
       " [u'gates'],\n",
       " [u'line'],\n",
       " [u'edsel'],\n",
       " [u'nobs'],\n",
       " [u'bidet'],\n",
       " [u'hagchet'],\n",
       " [u'pulley'],\n",
       " [u'quick'],\n",
       " [u'spreader'],\n",
       " [u'canapu'],\n",
       " [u'Lawnmowers'],\n",
       " [u'table'],\n",
       " [u'lamp'],\n",
       " [u'gates'],\n",
       " [u'canopy'],\n",
       " [u'tent'],\n",
       " [u'tresers'],\n",
       " [u'silicone'],\n",
       " [u'shopac'],\n",
       " [u'doorbell'],\n",
       " [u'fountains'],\n",
       " [u'fountains'],\n",
       " [u'cat'],\n",
       " [u'chandeliers'],\n",
       " [u'inserts'],\n",
       " [u'post'],\n",
       " [u'8x8'],\n",
       " [u'post'],\n",
       " [u'inserts'],\n",
       " [u'roller'],\n",
       " [u'respirator'],\n",
       " [u'roller'],\n",
       " [u'roundup'],\n",
       " [u'spreader'],\n",
       " [u'Lawnmowers'],\n",
       " [u'shoplight'],\n",
       " [u'spreader'],\n",
       " [u'safavieh'],\n",
       " [u'closetmaid'],\n",
       " [u'scaffolding'],\n",
       " [u'lockset'],\n",
       " [u'car'],\n",
       " [u'outdoorfurniture'],\n",
       " [u'wndows'],\n",
       " [u'microwaves'],\n",
       " [u'bidet'],\n",
       " [u'hagchet'],\n",
       " [u'canopy'],\n",
       " [u'or'],\n",
       " [u'saud'],\n",
       " [u'silicone'],\n",
       " [u'bidet'],\n",
       " [u'chandeliers'],\n",
       " [u'milwaukie'],\n",
       " [u'pulley'],\n",
       " [u'chaise'],\n",
       " [u'pembria'],\n",
       " [u'thermoplastic'],\n",
       " [u'coveralls'],\n",
       " [u'slatwall'],\n",
       " [u'chisel'],\n",
       " [u'microwaves'],\n",
       " [u'bidet'],\n",
       " [u'afakro'],\n",
       " [u'deckpaint'],\n",
       " [u'chandeliers'],\n",
       " [u'durock'],\n",
       " [u'rumbl;estone'],\n",
       " [u'flea'],\n",
       " [u'acrylic'],\n",
       " [u'bidet'],\n",
       " [u'deckpaint'],\n",
       " [u'spreader'],\n",
       " [u'quick'],\n",
       " [u'pulley'],\n",
       " [u'Acurio'],\n",
       " [u'wastel'],\n",
       " [u'marrazi'],\n",
       " [u'chisel'],\n",
       " [u'makita'],\n",
       " [u'parch'],\n",
       " [u'chairs'],\n",
       " [u'scaffolding'],\n",
       " [u'scaffoldings'],\n",
       " [u'chipper'],\n",
       " [u'roundup'],\n",
       " [u'chandeliers'],\n",
       " [u'standoffs'],\n",
       " [u'closetmaid'],\n",
       " [u'sinks'],\n",
       " [u'awnings'],\n",
       " [u'coveralls'],\n",
       " [u'durock'],\n",
       " [u'tubs'],\n",
       " [u'closetmade'],\n",
       " [u'closetmaid'],\n",
       " [u'lathe'],\n",
       " [u'closetmaid'],\n",
       " [u'shelfa'],\n",
       " [u'sjhelf'],\n",
       " [u'linzer'],\n",
       " [u'sinks'],\n",
       " [u'ffill'],\n",
       " [u'insallation'],\n",
       " [u'owens'],\n",
       " [u'Fuses'],\n",
       " [u'ribbon'],\n",
       " [u'closetmaid'],\n",
       " [u'chandeliers'],\n",
       " [u'lathe'],\n",
       " [u'demon'],\n",
       " [u'saud'],\n",
       " [u'paracord'],\n",
       " [u'frp'],\n",
       " [u'gates'],\n",
       " [u'pulley'],\n",
       " [u'gas'],\n",
       " [u'linzer'],\n",
       " [u'paracord'],\n",
       " [u'Fuses'],\n",
       " [u'canopy'],\n",
       " [u'chandeliers'],\n",
       " [u'azek'],\n",
       " [u'azek'],\n",
       " [u'nobs'],\n",
       " [u'table'],\n",
       " [u'car'],\n",
       " [u'miricale'],\n",
       " [u'lockset'],\n",
       " [u'Lawnmowers'],\n",
       " [u'deckpaint'],\n",
       " [u'blowers'],\n",
       " [u'hindges'],\n",
       " [u'crawley'],\n",
       " [u'4x6'],\n",
       " [u'taladros'],\n",
       " [u'glasses'],\n",
       " [u'banbury'],\n",
       " [u'roundup'],\n",
       " [u'makita'],\n",
       " [u'extractor'],\n",
       " [u'warmer'],\n",
       " [u't-hinge'],\n",
       " [u'sofet'],\n",
       " [u'acclaim'],\n",
       " [u'tji'],\n",
       " [u'caladiums'],\n",
       " [u'Buff'],\n",
       " [u'platforms'],\n",
       " [u'scaffolds'],\n",
       " [u'adorne'],\n",
       " [u'5/4x10'],\n",
       " [u'couchen'],\n",
       " [u'pantries'],\n",
       " [u'chime'],\n",
       " [u'STEAMFAST'],\n",
       " [u'drive'],\n",
       " [u'wallcoverings'],\n",
       " [u'linzer'],\n",
       " [u'shelterlogic'],\n",
       " [u'lightsensor'],\n",
       " [u'tar'],\n",
       " [u'non-skid'],\n",
       " [u'fyrpon'],\n",
       " [u'plum'],\n",
       " [u'tank'],\n",
       " [u'toprail'],\n",
       " [u'YARDGUARD'],\n",
       " [u'tresers'],\n",
       " [u'SedgeHammer'],\n",
       " [u'luever'],\n",
       " [u'closer'],\n",
       " [u'melnor'],\n",
       " [u'rachet'],\n",
       " [u'FrankeUSA'],\n",
       " [u'non-skid'],\n",
       " [u'hindges'],\n",
       " [u'everlast'],\n",
       " [u'sharkbit'],\n",
       " [u'backsplach'],\n",
       " [u'milwaukie'],\n",
       " [u'8x8'],\n",
       " [u'dimmable'],\n",
       " [u'sjhelf'],\n",
       " [u'counter'],\n",
       " [u'wyndham'],\n",
       " [u'grayson'],\n",
       " [u'halogen'],\n",
       " [u'demon'],\n",
       " [u'mushrooms'],\n",
       " [u'ringer'],\n",
       " [u'augers'],\n",
       " [u'dimmable'],\n",
       " [u'grills-gas'],\n",
       " [u'counter'],\n",
       " [u'shanko'],\n",
       " [u'magnetic'],\n",
       " [u'2x4x18'],\n",
       " [u'polycarbonite'],\n",
       " [u'winterizer'],\n",
       " [u'forimca'],\n",
       " [u'brinkhill'],\n",
       " [u'koolaroo'],\n",
       " [u'airstone'],\n",
       " [u'greenwich'],\n",
       " [u'muriatic'],\n",
       " [u'dvr'],\n",
       " [u'b-vent'],\n",
       " [u'YARDGUARD'],\n",
       " [u'spaonges'],\n",
       " [u'wndows'],\n",
       " [u'igloo'],\n",
       " [u'closer'],\n",
       " [u'heat'],\n",
       " [u'prefab'],\n",
       " [u'bakewarte'],\n",
       " [u'koolaroo'],\n",
       " [u'rasp'],\n",
       " [u'line'],\n",
       " [u'mixer'],\n",
       " [u'fuacet'],\n",
       " [u'wringer'],\n",
       " [u'flyer'],\n",
       " [u'bosh'],\n",
       " [u'transormations'],\n",
       " [u'laurey'],\n",
       " [u'beach'],\n",
       " [u'carboy'],\n",
       " [u'extractor'],\n",
       " [u'refrigerant'],\n",
       " [u'muriatic'],\n",
       " [u'nylon'],\n",
       " [u'realtree'],\n",
       " [u'FrankeUSA'],\n",
       " [u'repel'],\n",
       " [u'huskvarna'],\n",
       " [u'aspiradora'],\n",
       " [u'vacume'],\n",
       " [u'wet/dry'],\n",
       " [u'igloo'],\n",
       " [u'mixer'],\n",
       " [u'futon'],\n",
       " [u'bernzomatic'],\n",
       " [u'Buff'],\n",
       " [u'bollard'],\n",
       " [u'pruners'],\n",
       " [u'lids'],\n",
       " [u'doorway'],\n",
       " [u'heat'],\n",
       " [u'b-vent'],\n",
       " [u'ffill'],\n",
       " [u'desks'],\n",
       " [u'chess'],\n",
       " [u'ROUGE'],\n",
       " [u'plywoods'],\n",
       " [u'dolls'],\n",
       " [u'2x6x14'],\n",
       " [u'pods'],\n",
       " [u'line'],\n",
       " [u'aspiradora'],\n",
       " [u'biscayne'],\n",
       " [u'2x2x6'],\n",
       " [u'flyer'],\n",
       " [u'wiremesh'],\n",
       " [u'sauder'],\n",
       " [u'drils'],\n",
       " [u'ornaments'],\n",
       " [u'knob'],\n",
       " [u'bathrooms'],\n",
       " [u'plywoods'],\n",
       " [u'tank'],\n",
       " [u'gnat'],\n",
       " [u'tan'],\n",
       " [u'FrankeUSA'],\n",
       " [u'bernzomatic'],\n",
       " [u'barns'],\n",
       " [u'adorne'],\n",
       " [u'adrone'],\n",
       " [u'riddex'],\n",
       " [u'step'],\n",
       " [u'madeline'],\n",
       " [u'POPPIES'],\n",
       " [u'adorne'],\n",
       " [u'adrone'],\n",
       " [u'lakeshore'],\n",
       " [u'flea'],\n",
       " [u'camping'],\n",
       " [u'laminet'],\n",
       " [u'sheffield'],\n",
       " [u'dolls'],\n",
       " [u'mixer'],\n",
       " [u'hedgers'],\n",
       " [u'memoirs'],\n",
       " [u'ibeam'],\n",
       " [u'peak'],\n",
       " [u'laminated'],\n",
       " [u'storeage'],\n",
       " [u'transormations'],\n",
       " [u'car'],\n",
       " [u'chime'],\n",
       " [u'emsco'],\n",
       " [u'deckpaint'],\n",
       " [u'gas'],\n",
       " [u'hudson'],\n",
       " [u'eureka'],\n",
       " [u'seals'],\n",
       " [u'toter'],\n",
       " [u'r-30'],\n",
       " [u'b-vent'],\n",
       " [u'homeline'],\n",
       " [u'chamois'],\n",
       " [u'Buff'],\n",
       " [u'handtools'],\n",
       " [u'bird-x'],\n",
       " [u'riddex'],\n",
       " [u'glasses'],\n",
       " [u'backsplach'],\n",
       " [u'greenwich'],\n",
       " [u'weed'],\n",
       " [u'or'],\n",
       " [u'alarm'],\n",
       " [u'surebond'],\n",
       " [u'bakewarte'],\n",
       " [u'pantries'],\n",
       " [u'8x8'],\n",
       " [u'grqss'],\n",
       " [u'sweep'],\n",
       " [u'silverton'],\n",
       " [u'pentas'],\n",
       " [u'candles'],\n",
       " [u'counter'],\n",
       " [u'wet/dry'],\n",
       " [u'or'],\n",
       " [u'phillits'],\n",
       " [u'camping'],\n",
       " [u'toprail'],\n",
       " [u'artificial'],\n",
       " [u'nut'],\n",
       " [u'21x21x1'],\n",
       " [u'medalion'],\n",
       " [u'To'],\n",
       " [u'shaw'],\n",
       " [u'chevron'],\n",
       " [u'showcase'],\n",
       " [u'car'],\n",
       " [u'exteria'],\n",
       " [u'outdoorfurniture'],\n",
       " [u'everlast'],\n",
       " [u'non-skid'],\n",
       " [u'artificial'],\n",
       " [u'symmons'],\n",
       " [u'toprail'],\n",
       " [u'halogen'],\n",
       " [u'coveralls'],\n",
       " [u'standoffs'],\n",
       " [u'shelterlogic'],\n",
       " [u'branches'],\n",
       " [u'flyer'],\n",
       " [u'augers'],\n",
       " [u'driveway'],\n",
       " [u'cr'],\n",
       " [u'valance'],\n",
       " [u'marrazi'],\n",
       " [u'midea'],\n",
       " [u'Buff'],\n",
       " [u'urethane'],\n",
       " [u'triplex'],\n",
       " [u'canyon'],\n",
       " [u'lakeshore'],\n",
       " [u'storeage'],\n",
       " [u'blenders'],\n",
       " [u'airstone'],\n",
       " [u'venner'],\n",
       " [u'ecosinks'],\n",
       " [u'polycarbonite'],\n",
       " [u'shakewood'],\n",
       " [u'kitchenfaucet'],\n",
       " [u'handtools'],\n",
       " [u'backsplach'],\n",
       " [u'omnifilter'],\n",
       " [u'adorne'],\n",
       " [u'staircase'],\n",
       " [u'boat'],\n",
       " [u'marine'],\n",
       " [u'unsulation'],\n",
       " [u'pediments'],\n",
       " [u'couchen'],\n",
       " [u'bird-x'],\n",
       " [u'Bunting'],\n",
       " [u'airblown'],\n",
       " [u'sticker'],\n",
       " [u'home-flex'],\n",
       " [u'shanko'],\n",
       " [u'manual'],\n",
       " [u'prefab'],\n",
       " [u'placemat'],\n",
       " [u'e-310'],\n",
       " [u'plumber'],\n",
       " [u'milwaukie'],\n",
       " [u'sawall'],\n",
       " [u'mastercool'],\n",
       " [u'crawley'],\n",
       " [u'ion'],\n",
       " [u'standoffs'],\n",
       " [u'candles'],\n",
       " [u'non-skid'],\n",
       " [u'sunshield'],\n",
       " [u'replacement'],\n",
       " [u'canapu'],\n",
       " [u'willow'],\n",
       " [u'Hearth'],\n",
       " [u'barns'],\n",
       " [u'pembria'],\n",
       " [u'shelterlogic'],\n",
       " [u'extractor'],\n",
       " [u'thermoplastic'],\n",
       " [u'dustpans'],\n",
       " [u'safety'],\n",
       " [u'tar'],\n",
       " [u'broiler'],\n",
       " [u'sharkbit'],\n",
       " [u'symmons'],\n",
       " [u'plywoods'],\n",
       " [u'fairy'],\n",
       " [u'downrod'],\n",
       " [u'monticello'],\n",
       " [u'heat'],\n",
       " [u'bug'],\n",
       " [u'valance'],\n",
       " [u'knaack'],\n",
       " [u'disposer'],\n",
       " [u'garde'],\n",
       " [u'acacia'],\n",
       " [u'canyon'],\n",
       " [u'wringer'],\n",
       " [u'margarita'],\n",
       " [u'backsplach'],\n",
       " [u'durham'],\n",
       " [u'ratchet'],\n",
       " [u'disposer'],\n",
       " [u'ridx'],\n",
       " [u'hudson'],\n",
       " [u'tank'],\n",
       " [u'sonicrafter'],\n",
       " [u'backsplach'],\n",
       " [u'rainbarrel'],\n",
       " [u'14x14'],\n",
       " [u'chamois'],\n",
       " [u'roxul'],\n",
       " [u'rasp'],\n",
       " [u'dvr'],\n",
       " [u'vikrell'],\n",
       " [u'platforms'],\n",
       " [u'gas'],\n",
       " [u'app'],\n",
       " [u'itwinkle'],\n",
       " [u'collapsible'],\n",
       " [u'sharkbit'],\n",
       " [u'mtd'],\n",
       " [u'parch'],\n",
       " [u'SedgeHammer'],\n",
       " [u'bandana'],\n",
       " [u'bernzomatic'],\n",
       " [u'dimmable'],\n",
       " [u'4*4'],\n",
       " [u'weman'],\n",
       " [u'daconil'],\n",
       " [u'shanko'],\n",
       " [u'valance'],\n",
       " [u'MASKING'],\n",
       " [u'quick'],\n",
       " [u'surebond'],\n",
       " [u'brayer'],\n",
       " [u'fen'],\n",
       " [u'rhododendrons'],\n",
       " [u'madeline'],\n",
       " [u'vanguard'],\n",
       " [u'YARDGUARD'],\n",
       " [u'igloo'],\n",
       " [u'barns'],\n",
       " [u'didger'],\n",
       " [u'tomostat'],\n",
       " [u'muriatic'],\n",
       " [u'pediments'],\n",
       " [u'downlight'],\n",
       " [u'wheelbarrows'],\n",
       " [u'bosh'],\n",
       " [u'baseboarders'],\n",
       " [u'pods'],\n",
       " [u'stairtreads'],\n",
       " [u'terminator'],\n",
       " [u'beech'],\n",
       " [u'artificial'],\n",
       " [u'bateries'],\n",
       " [u'throw'],\n",
       " [u'plywoods'],\n",
       " [u'surebond'],\n",
       " [u'extractor'],\n",
       " [u'greenhouses'],\n",
       " [u'SedgeHammer'],\n",
       " [u'shelfa'],\n",
       " [u'flexible'],\n",
       " [u'versa'],\n",
       " [u'bathrooms'],\n",
       " [u'STEAMFAST'],\n",
       " [u'medical'],\n",
       " [u'repel'],\n",
       " [u'flea'],\n",
       " [u'80/7'],\n",
       " [u'prices'],\n",
       " [u'aspiradora'],\n",
       " [u'gardenias'],\n",
       " [u'ceadar'],\n",
       " [u'cornerstone'],\n",
       " [u'12x12'],\n",
       " [u'bathrooms'],\n",
       " [u'alder'],\n",
       " [u'triplex'],\n",
       " [u'gardinias'],\n",
       " [u'lightsensor'],\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_by_num_words = defaultdict(list)\n",
    "for search_term in search_terms_train + search_terms_test:\n",
    "    search_by_num_words[len(search_term)].append(search_term)\n",
    "search_by_num_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train.relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge training and testing data sets to single dataframe\n",
    "\n",
    "df_train_copy = df_train.drop('relevance', axis=1)\n",
    "df_train_copy['dataset'] = 'train'\n",
    "\n",
    "df_test_copy = df_test.copy()\n",
    "df_test_copy['dataset'] = 'test'\n",
    "\n",
    "df = pd.concat([df_train_copy, df_test_copy], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are all products in product description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_uids = set(df_des.product_uid.values)\n",
    "len(filter(lambda uid: uid in unique_uids, df.product_uid.values)) / float(len(df.product_uid.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data with descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>dataset</th>\n",
       "      <th>product_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>train</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>train</td>\n",
       "      <td>Not only do angles make joints stronger, they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>train</td>\n",
       "      <td>BEHR Premium Textured DECKOVER is an innovativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>train</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>train</td>\n",
       "      <td>Update your bathroom with the Delta Vero Singl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1   3       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2   9       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3  16       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4  17       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "\n",
       "          search_term dataset  \\\n",
       "0       angle bracket   train   \n",
       "1           l bracket   train   \n",
       "2           deck over   train   \n",
       "3    rain shower head   train   \n",
       "4  shower only faucet   train   \n",
       "\n",
       "                                 product_description  \n",
       "0  Not only do angles make joints stronger, they ...  \n",
       "1  Not only do angles make joints stronger, they ...  \n",
       "2  BEHR Premium Textured DECKOVER is an innovativ...  \n",
       "3  Update your bathroom with the Delta Vero Singl...  \n",
       "4  Update your bathroom with the Delta Vero Singl...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_des, how='left', on='product_uid')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pivoted_attributes = get_attributes_pivoted_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# pattern_replace = []\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?)(-?)(in\\s|in\\.?\\s|inchs?|inches)(?i)', r'\\1inch '))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(ft\\.?|foot|feet)(?i)', r'\\1ft.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(pounds?|lb\\.?)(?i)', r'\\1lb.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(square|sq)(\\.?\\s?)(ft\\.?|foot|feet)(?i)', r'\\1sq.ft.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(cubic|cu)(\\.?\\s?)(ft\\.?|foot|feet)(?i)', r'\\1cu.ft.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(gallons?|gal\\.?)(?i)', r'\\1gal.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(ounces?|ounce|oz\\.?)(?i)', r'\\1oz.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(amperes?|amp\\.?s?)(?i)', r'\\1amp.'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(volt|volts)(?i)', r'\\1volts'))            \n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(watt|watts)(?i)', r'\\1watts'))\n",
    "# pattern_replace.append(('(\\d?_/?\\d)(\\s?-?)(mm\\.?|millimeter)(?i)', r'\\1mm'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(cm\\.?|centimeter)(?i)', r'\\1cm'))\n",
    "# pattern_replace.append(('(\\d?/?\\d)(\\s?-?)(m\\.?|meter)(?i)', r'\\1m'))\n",
    "# pattern_replace.append(('-', ' '))    \n",
    "# pattern_replace.append(('(\\(|\\))', ''))\n",
    "# pattern_replace.append(('refridgerator', 'fridge'))\n",
    "# pattern_replace.append(('refridgerator', 'fridge'))\n",
    "# pattern_replace.append(('(\\d)(\")', '\\1inch')) \n",
    "# pattern_replace.append((\"(\\d)(')\", '\\1ft.'))\n",
    "# pattern_replace.append((\" x \", ' x')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for (pattern, replace) in pattern_replace:\n",
    "    \n",
    "#     print 'pattern: {}'.format(pattern)\n",
    "#     print 'modified elements [search]: {}'.format(\n",
    "#         len([search for search in df1.search_term if re.search(pattern, search)]))\n",
    "\n",
    "#     print 'modified elements [product-title]: {}'.format(\n",
    "#         len([search for search in df1.product_title if re.search(pattern, search)]))\n",
    "        \n",
    "#     orig_rep_search = [(search, re.sub(pattern, replace, search)) \n",
    "#                        for search in df1.search_term if re.search(pattern, search)]\n",
    "\n",
    "#     orig_rep_title = [(product_title, re.sub(pattern, replace, product_title)) \n",
    "#                       for product_title in df1.product_title if re.search(pattern, product_title)]\n",
    "        \n",
    "#     df1.search_term = df1.search_term.map(lambda x: re.sub(pattern, replace, x))\n",
    "    \n",
    "#     df1.product_title = df1.product_title.map(lambda x: re.sub(pattern, replace, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "import unicodedata\n",
    "strNum = {'zero':0,'one':1,'two':2,'three':3,'four':4,'five':5,'six':6,'seven':7,'eight':8,'nine':9}\n",
    "\n",
    "def str_stem(s):\n",
    "    s = unicodedata.normalize('NFD', unicode(s)).encode('ascii', 'ignore')\n",
    "    s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\",\", \"\") #could be number / segment later\n",
    "    s = s.replace(\"$\", \" \")\n",
    "    s = s.replace(\"?\", \" \")\n",
    "    s = s.replace(\"-\", \" \")\n",
    "    s = s.replace(\"//\", \"/\")\n",
    "    s = s.replace(\"..\", \".\")\n",
    "    s = s.replace(\" / \", \" \")\n",
    "    s = s.replace(\" \\\\ \", \" \")\n",
    "    s = s.replace(\".\", \" . \")\n",
    "    s = re.sub(r\"(^\\.|/)\", r\"\", s)\n",
    "    s = re.sub(r\"(\\.|/)$\", r\"\", s)\n",
    "    s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "    s = s.replace(\" x \", \" xbi \")\n",
    "    s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = s.replace(\"*\", \" xbi \")\n",
    "    s = s.replace(\" by \", \" xbi \")\n",
    "    s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "    s = s.replace(\"°\", \" degrees \")\n",
    "    s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n",
    "    s = s.replace(\" v \", \" volts \")\n",
    "    s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n",
    "    s = s.replace(\"  \", \" \")\n",
    "    s = s.replace(\" . \", \" \")\n",
    "    s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n",
    "    s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"toliet\", \"toilet\")\n",
    "    s = s.replace(\"airconditioner\", \"air conditioner\")\n",
    "    s = s.replace(\"vinal\", \"vinyl\")\n",
    "    s = s.replace(\"vynal\", \"vinyl\")\n",
    "    s = s.replace(\"skill\", \"skil\")\n",
    "    s = s.replace(\"snowbl\", \"snow bl\")\n",
    "    s = s.replace(\"plexigla\", \"plexi gla\")\n",
    "    s = s.replace(\"rustoleum\", \"rust oleum\")\n",
    "    s = s.replace(\"whirpool\", \"whirlpool\")\n",
    "    s = s.replace(\"whirlpoolga\", \"whirlpool ga\")\n",
    "    s = s.replace(\"whirlpoolstainless\", \"whirlpool stainless\")\n",
    "    return s\n",
    "\n",
    "df1.search_term = df1.search_term.map(str_stem)\n",
    "df1.product_title = df1.product_title.map(str_stem)\n",
    "df_att.value = df_att.value.map(str_stem)\n",
    "# df1.product_description = df1.product_description.map(str_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data with attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_attributes_pivoted_df():\n",
    "\n",
    "    def filter_attributes(row):\n",
    "        if (row[0], row[1]) in filter_set:\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "    by_attribute = df_att.groupby(['product_uid', 'name']).count()\n",
    "    filter_set = by_attribute[by_attribute.value > 1].reset_index()[['product_uid', 'name']].values\n",
    "    filter_set = set([(uid, name) for uid, name in filter_set.tolist()])\n",
    "    \n",
    "    _df = df_att.copy()\n",
    "    _df['keep'] = df_att.apply(filter_attributes, axis=1)\n",
    "    _df = _df[_df['keep'] == 1]\n",
    "    _df = _df.dropna(how='any')\n",
    "    _df = _df.pivot(index='product_uid', columns='name', values='value')\n",
    "    _df.reset_index(inplace=True)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis - TF-IDF + TSVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def lemma(word):\n",
    "    try:\n",
    "        return lmtzr.lemmatize(word.encode('ascii', 'ignore'))\n",
    "    except:\n",
    "        return word\n",
    "    \n",
    "def text_transformer(_df, _field):\n",
    "\n",
    "    text_array = _df[_field]\n",
    "    text_array_copy = text_array.map(lambda words: ' '.join([lemma(word) for word in words.split(' ')]))\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "    tsvd = TruncatedSVD(n_components=10, random_state=0)\n",
    "    \n",
    "    tfidf.fit(text_array)\n",
    "    mx_tfidf = tfidf.transform(text_array)\n",
    "    \n",
    "    tsvd.fit(mx_tfidf)\n",
    "    tsvd_tfidf = tsvd.transform(mx_tfidf)\n",
    "    \n",
    "    return tsvd_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_terms_ns = text_transformer(df1, 'search_term')\n",
    "product_titles_ns = text_transformer(df1, 'product_title')\n",
    "# product_description_ns = text_transformer(df1, 'product_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_search_terms = pd.DataFrame(search_terms_ns, index=df1.index, columns=['search_term_ns_' + str(x) \n",
    "                                                         for x in xrange(search_terms_ns.shape[1])])\n",
    "df_product_titles = pd.DataFrame(product_titles_ns, index=df1.index, columns=['product_titles_ns_' + str(x) \n",
    "                                                         for x in xrange(product_titles_ns.shape[1])])\n",
    "# df_product_descriptions = pd.DataFrame(product_description_ns, index=df1.index, columns=['product_description_ns_' + str(x) \n",
    "#                                                          for x in xrange(product_description_ns.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, df_search_terms, df_product_titles], axis=1, ignore_index=False)\n",
    "# df1 = pd.concat([df1, df_search_terms, df_product_titles, df_product_descriptions], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Score by Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_terms = []\n",
    "search_terms_cum_score = defaultdict(int)\n",
    "\n",
    "for search, score in zip(df1.search_term, y_train):\n",
    "    for term in map(lambda x: x.strip(), search.split(' ')):\n",
    "        search_terms.append(term)\n",
    "        search_terms_cum_score[term] += score\n",
    "        \n",
    "term_counts = sorted(Counter(search_terms).items(), key=lambda x: x[1], reverse=True)\n",
    "terms, counts = zip(*term_counts)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_score_by_term = dict()\n",
    "for term, count in zip(terms, counts):\n",
    "    mean_score_by_term[term] = search_terms_cum_score[term] / float(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_score = np.mean(y_train)\n",
    "\n",
    "def term_avg_score(searches):\n",
    "    output_array = []\n",
    "    for search in searches:\n",
    "        cum_score = 0\n",
    "        term_count = 0\n",
    "        for term in map(lambda x: x.strip(), search.split(' ')):\n",
    "            if term in mean_score_by_term:\n",
    "                cum_score += mean_score_by_term[term]\n",
    "                term_count += 1\n",
    "        \n",
    "        if term_count > 0:\n",
    "            output_array.append(cum_score / float(term_count))\n",
    "        else:\n",
    "            output_array.append(baseline_score)\n",
    "        \n",
    "    return output_array\n",
    "\n",
    "df1['term_avg_score'] = term_avg_score(df1.search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comment out after use\n",
    "# df1 = df1_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "stopwords_eng = set(stopwords.words(\"english\"))\n",
    "nan_arrays = []\n",
    "\n",
    "def ratio_words_matched(searches, match_phrases, ids, remove_stopwords=False, \n",
    "                        lemma=False, singularize=False, denominator='search'):\n",
    "    \n",
    "    output_array = []\n",
    "    for search_terms, match_phrase, _id in zip(searches, match_phrases, ids):\n",
    "        \n",
    "        if isinstance(match_phrase, float) and math.isnan(match_phrase):\n",
    "            nan_arrays.append((search_terms, match_phrase))\n",
    "            output_array.append(0)\n",
    "        else:\n",
    "            \n",
    "            a = search_terms\n",
    "            b = match_phrase\n",
    "            \n",
    "            try:\n",
    "                search_terms = search_terms.encode('ascii','ignore')\n",
    "                search_terms = str(search_terms)\n",
    "                search_terms = search_terms.lower()\n",
    "                \n",
    "                match_phrase = match_phrase.encode('ascii','ignore')\n",
    "                match_phrase = str(match_phrase)\n",
    "                match_phrase = match_phrase.lower()\n",
    "            except:\n",
    "                print 'error in encoding: {}, {}, {}'.format(search_terms, match_phrase, _id)\n",
    "                output_array.append(0)\n",
    "                pdb.set_trace()\n",
    "                continue\n",
    "            \n",
    "            if remove_stopwords:\n",
    "                search_terms = ' '.join([word for word in search_terms.split() if word not in stopwords_eng])\n",
    "                match_phrase = ' '.join([word for word in match_phrase.split() if word not in stopwords_eng])\n",
    "                \n",
    "            search_words = [term for term in search_terms.split() if term.strip() != '']\n",
    "            match_phrase_words = [term for term in match_phrase.split() if term.strip() != '']\n",
    "                     \n",
    "            if denominator == 'search':\n",
    "                num_matches = sum([1 for word in search_words if word in match_phrase_words])\n",
    "                \n",
    "                if len(search_words) > 0:\n",
    "                    output_array.append(num_matches / float(len(search_words))) \n",
    "                else:\n",
    "                    output_array.append(0)\n",
    "            else:\n",
    "                num_matches = sum([1 for word in match_phrase_words if word in search_words])\n",
    "                if len(search_words) > 0:\n",
    "                    output_array.append(num_matches / float(len(match_phrase_words))) \n",
    "                else:\n",
    "                    output_array.append(0)\n",
    "                \n",
    "    return output_array\n",
    "\n",
    "def num_chars_in_search(searches, remove_stopwords=False, remove_numeric_units=False):\n",
    "    \n",
    "    output_array = []\n",
    "    for search_terms in searches:\n",
    "        if remove_stopwords:\n",
    "            search_terms = ' '.join([word for word in search_terms.split() if word not in stopwords_eng])\n",
    "        if remove_numeric_units:\n",
    "            search_terms = ' '.join([word for word in search_terms.split() if word not in trivial_terms])\n",
    "        output_array.append(len(search_terms))\n",
    "    return output_array      \n",
    "\n",
    "def num_stopwords_in_search(searches):\n",
    "    output_array = []\n",
    "    for search_terms in searches:\n",
    "        _stopwords = [word for word in search_terms.split() if word in stopwords_eng]\n",
    "        output_array.append(len(_stopwords))\n",
    "    return output_array      \n",
    "\n",
    "def attribute_match(attribute):\n",
    "    \n",
    "    _df_merged = pd.merge(df1, df_pivoted_attributes[['product_uid', attribute]], how='left', on='product_uid')\n",
    "    output_array = ratio_words_matched(_df_merged.search_term, _df_merged[attribute], _df_merged.index)\n",
    "    \n",
    "    return [1 if x > 0 else 0 for x in output_array]\n",
    "\n",
    "def nth_word_matched(searches, match_phrases, n):\n",
    "    \n",
    "    if n == 0:\n",
    "        raise ValueError('input n must be greater than 0')\n",
    "    \n",
    "    stopwords_eng = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    output_array = []\n",
    "    for search_phrase, match_phrase in zip(searches, match_phrases):\n",
    "        \n",
    "        search_terms = search_phrase.split()\n",
    "        \n",
    "        # if there are n words\n",
    "        if n > len(search_terms) or search_terms[n-1] in stopwords_eng:\n",
    "            output_array.append(-1)\n",
    "        elif search_terms[n-1] in match_phrase:\n",
    "            output_array.append(1)\n",
    "        else:\n",
    "            output_array.append(0)\n",
    "    \n",
    "    print 'n: {}, counter: {}'.format(n, Counter(output_array))\n",
    "    return output_array      \n",
    "\n",
    "def word_matched(searches, match_phrases):\n",
    "    \n",
    "    output_array = []\n",
    "    stopwords_eng = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    for search, phrase in zip(searches, match_phrases):\n",
    "        last_word = search.split()[-1]\n",
    "        if last_word not in stopwords_eng and last_word in phrase.split():\n",
    "            output_array.append(1)\n",
    "        else:\n",
    "            output_array.append(0)\n",
    "        \n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5410"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pivoted_attributes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n"
     ]
    }
   ],
   "source": [
    "column_counts = []\n",
    "column_uniques = []\n",
    "count = 0\n",
    "for column in df_pivoted_attributes.columns:\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print count\n",
    "    \n",
    "    column_counts.append((column, \n",
    "                          df_pivoted_attributes[column].count(), \n",
    "                          len(df_pivoted_attributes[column].unique())))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Package Quantity', 6904, 282),\n",
       " (u'Bullet13', 6348, 2037),\n",
       " (u'Flooring Product Type', 6230, 93),\n",
       " (u'Color', 6214, 1314),\n",
       " (u'Tools Product Type', 6169, 14),\n",
       " (u'Included', 6079, 153),\n",
       " (u'Voltage (volts)', 6068, 105),\n",
       " (u'Assembly Required', 5718, 3),\n",
       " (u'Features', 5562, 530),\n",
       " (u'Wattage (watts)', 5107, 434),\n",
       " (u'Finish', 4996, 667),\n",
       " (u'Shape', 4876, 52),\n",
       " (u'Color/Finish Family', 4628, 74),\n",
       " (u'Electrical Product Type', 4409, 143),\n",
       " (u'Finish Family', 4209, 54),\n",
       " (u'Fixture Color/Finish', 4117, 764),\n",
       " (u'Product Thickness (in.)', 4080, 505),\n",
       " (u'Style', 4057, 32),\n",
       " (u'Interior/Exterior', 3950, 5),\n",
       " (u'Bullet14', 3853, 1447),\n",
       " (u'Number of Bulbs Required', 3802, 44),\n",
       " (u'Coverage Area (sq. ft.)', 3756, 276),\n",
       " (u'Finish Type', 3658, 18),\n",
       " (u'Power Tool Product Type', 3442, 20),\n",
       " (u'Paint Product Type', 3427, 114),\n",
       " (u'Outdoor Living Product Type', 3395, 127),\n",
       " (u'Collection Name', 3361, 765),\n",
       " (u'Hardware Finish Family', 3355, 23),\n",
       " (u'Bulb Type Included', 3331, 18),\n",
       " (u'Reconditioned', 3254, 3),\n",
       " (u'Light Source', 3204, 11),\n",
       " (u'Amperage (amps)', 3175, 281),\n",
       " (u'Paint/Stain Key Features', 3168, 97),\n",
       " (u'Container Size', 3128, 35),\n",
       " (u'Bulb Type', 3120, 19),\n",
       " (u'Bullet20', 3120, 41),\n",
       " (u'Dry to touch (min.)', 3117, 34),\n",
       " (u'Light Bulb Base Code', 2988, 42),\n",
       " (u'Fastener Type', 2982, 96),\n",
       " (u'Bullet15', 2913, 1063),\n",
       " (u'Bullet18', 2859, 238),\n",
       " (u'Product Thickness (mm)', 2823, 165),\n",
       " (u'Builders Hardware Product Type', 2785, 77),\n",
       " (u'Transparency', 2713, 6),\n",
       " (u'Paint/Stain Clean Up', 2686, 5),\n",
       " (u'Door Handing', 2533, 14),\n",
       " (u'Sheen', 2497, 10),\n",
       " (u'Weight Capacity (lb.)', 2497, 229),\n",
       " (u'Adjustable Lamp Head', 2485, 3),\n",
       " (u'Time before recoating (hours)', 2342, 29),\n",
       " (u'Appliance Type', 2322, 71),\n",
       " (u'Frame Material', 2290, 26),\n",
       " (u'Number of Doors', 2282, 8),\n",
       " (u'Fixture Color/Finish Family', 2256, 22),\n",
       " (u'Product Length (ft.)', 2241, 324),\n",
       " (u'Maximum Wattage (watts)', 2221, 62),\n",
       " (u'Weather Resistant', 2134, 3),\n",
       " (u'Door Type', 2099, 28),\n",
       " (u'Number of Pieces', 2061, 112),\n",
       " (u'Approximate Tile Size', 2036, 52),\n",
       " (u'Faucet type', 2019, 11),\n",
       " (u'Shade Color Family', 2006, 24),\n",
       " (u'Size', 2003, 116),\n",
       " (u'Decor Product Type', 2000, 20),\n",
       " (u'Application Type', 1975, 71),\n",
       " (u'Paintable/Stainable', 1955, 3),\n",
       " (u'RGB Value', 1937, 1126),\n",
       " (u'Flow rate (gallons per minute)', 1920, 58),\n",
       " (u'Bullet16', 1896, 716),\n",
       " (u'Kitchen Product Type', 1895, 102)]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(column_counts, key=lambda x: x[1], reverse=True)[30:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort items to ranking of popularity common brands buckets\n",
    "def rank_by_count(attribute):\n",
    "    \n",
    "    rank_lookup = dict()\n",
    "    for i, (key, _) in enumerate(sorted(Counter(df_pivoted_attributes[attribute]).items(), \n",
    "                                        key=lambda x: x[1], reverse=True)):\n",
    "        rank_lookup[key] = i\n",
    "                                 \n",
    "    return rank_lookup                     \n",
    "\n",
    "# commoness of attributes\n",
    "rank_lookup_brand = rank_by_count('MFG Brand Name')\n",
    "rank_lookup_color = rank_by_count('Color Family')\n",
    "rank_lookup_material = rank_by_count('Material')\n",
    "rank_lookup_finish = rank_by_count('Color/Finish')\n",
    "\n",
    "df_pivoted_attributes['brand_c_index'] = df_pivoted_attributes['MFG Brand Name'].map(lambda x: rank_lookup_brand[x])\n",
    "df_pivoted_attributes['color_c_index'] = df_pivoted_attributes['Color Family'].map(lambda x: rank_lookup_color[x])\n",
    "df_pivoted_attributes['material_c_index'] = df_pivoted_attributes['Material'].map(lambda x: rank_lookup_material[x])\n",
    "df_pivoted_attributes['finish_c_index'] = df_pivoted_attributes['Color/Finish'].map(lambda x: rank_lookup_finish[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numpy_strings = np.array(df.search_term.map(lambda x: nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[u'angle', u'bracket'], [u'l', u'bracket'], [u'deck', u'over'],\n",
       "       [u'rain', u'shower', u'head'], [u'shower', u'only', u'faucet'],\n",
       "       [u'convection', u'otr'], [u'microwave', u'over', u'stove'],\n",
       "       [u'microwaves'], [u'emergency', u'light'], [u'mdf', u'3/4']], dtype=object)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_strings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'door', 8708),\n",
       " (u'in', 6064),\n",
       " (u'light', 5943),\n",
       " (u'for', 5014),\n",
       " (u'shower', 4798),\n",
       " (u'inch', 4649),\n",
       " (u'x', 4442),\n",
       " (u'tile', 4351),\n",
       " (u'wall', 4207),\n",
       " (u'white', 4133),\n",
       " (u'wood', 4130),\n",
       " (u'with', 3708),\n",
       " (u\"'\", 3567),\n",
       " (u'and', 3548),\n",
       " (u'paint', 3525),\n",
       " (u'outdoor', 3249),\n",
       " (u'water', 3242),\n",
       " (u'bathroom', 3100),\n",
       " (u'doors', 2983),\n",
       " (u'cabinet', 2968),\n",
       " (u'vanity', 2914),\n",
       " (u'4', 2882),\n",
       " (u'kitchen', 2845),\n",
       " (u'2', 2820),\n",
       " (u'gas', 2758),\n",
       " (u'lights', 2695),\n",
       " (u'floor', 2689),\n",
       " (u'1/2', 2641),\n",
       " (u'air', 2589),\n",
       " (u'black', 2587),\n",
       " (u'sink', 2568),\n",
       " (u'ceiling', 2513),\n",
       " (u'kit', 2496),\n",
       " (u'fan', 2495),\n",
       " (u'led', 2490),\n",
       " (u'pipe', 2356),\n",
       " (u'steel', 2304),\n",
       " (u'window', 2268),\n",
       " (u'faucet', 2255),\n",
       " (u'1', 2241),\n",
       " (u'glass', 2172),\n",
       " (u'patio', 2097),\n",
       " (u'.', 2045),\n",
       " (u'saw', 2043),\n",
       " (u'lighting', 1993),\n",
       " (u'3', 1993),\n",
       " (u'metal', 1990),\n",
       " (u'pvc', 1982),\n",
       " (u'heater', 1972),\n",
       " (u'6', 1963),\n",
       " (u'electric', 1908),\n",
       " (u'12', 1887),\n",
       " (u'wire', 1840),\n",
       " (u'toilet', 1803),\n",
       " (u'tub', 1752),\n",
       " (u'fence', 1685),\n",
       " (u'vinyl', 1665),\n",
       " (u'plastic', 1601),\n",
       " (u'3/4', 1589),\n",
       " (u'cover', 1554),\n",
       " (u'top', 1534),\n",
       " (u'drill', 1514),\n",
       " (u'bay', 1488),\n",
       " (u'post', 1430),\n",
       " (u'storage', 1430),\n",
       " (u'stainless', 1424),\n",
       " (u'hose', 1412),\n",
       " (u'box', 1406),\n",
       " (u'bronze', 1404),\n",
       " (u'set', 1391),\n",
       " (u'panel', 1384),\n",
       " (u'tool', 1377),\n",
       " (u'filter', 1351),\n",
       " (u'8', 1338),\n",
       " (u'base', 1328),\n",
       " (u'1/4', 1327),\n",
       " (u'bath', 1313),\n",
       " (u'10', 1311),\n",
       " (u'30', 1306),\n",
       " (u'24', 1277),\n",
       " (u'interior', 1270),\n",
       " (u'bulb', 1255),\n",
       " (u'range', 1246),\n",
       " (u'battery', 1242),\n",
       " (u'table', 1227),\n",
       " (u'36', 1226),\n",
       " (u'double', 1225),\n",
       " (u'ft', 1224),\n",
       " (u'trim', 1223),\n",
       " (u'hampton', 1203),\n",
       " (u'cabinets', 1198),\n",
       " (u'garden', 1197),\n",
       " (u'drain', 1185),\n",
       " (u'washer', 1180),\n",
       " (u'garage', 1172),\n",
       " (u'exterior', 1172),\n",
       " (u'mount', 1163),\n",
       " (u'screen', 1148),\n",
       " (u'deck', 1141),\n",
       " (u'spray', 1137)]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([word for words in numpy_strings for word in words]).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(nan, 32611),\n",
       " (u'1', 1691),\n",
       " (u'2', 1442),\n",
       " (u'3', 1245),\n",
       " (u'4', 1007),\n",
       " (u'1.5', 880),\n",
       " (u'12', 851),\n",
       " (u'6', 785),\n",
       " (u'0.5', 767),\n",
       " (u'5', 766),\n",
       " (u'2.5', 737),\n",
       " (u'24', 690),\n",
       " (u'0.75', 671),\n",
       " (u'3.5', 657),\n",
       " (u'8', 623),\n",
       " (u'1.25', 577),\n",
       " (u'7', 554),\n",
       " (u'10', 543),\n",
       " (u'0.25', 542),\n",
       " (u'1.75', 498),\n",
       " (u'18', 489),\n",
       " (u'4.5', 486),\n",
       " (u'9', 478),\n",
       " (u'14', 469),\n",
       " (u'16', 468),\n",
       " (u'22', 398),\n",
       " (u'2.25', 377),\n",
       " (u'5.5', 361),\n",
       " (u'48', 361),\n",
       " (u'6.5', 345),\n",
       " (u'15', 343),\n",
       " (u'3.25', 336),\n",
       " (u'11', 323),\n",
       " (u'20', 317),\n",
       " (u'13', 314),\n",
       " (u'2.75', 310),\n",
       " (u'0.625', 290),\n",
       " (u'7.5', 288),\n",
       " (u'1.125', 259),\n",
       " (u'96', 250),\n",
       " (u'36', 249),\n",
       " (u'30', 247),\n",
       " (u'3.75', 235),\n",
       " (u'8.5', 233),\n",
       " (u'0.01', 227),\n",
       " (u'4.75', 218),\n",
       " (u'17', 217),\n",
       " (u'21', 216),\n",
       " (u'0.125', 215),\n",
       " (u'19', 200),\n",
       " (u'12.5', 197),\n",
       " (u'9.5', 194),\n",
       " (u'10.5', 176),\n",
       " (u'0.375', 171),\n",
       " (u'0', 164),\n",
       " (u'60', 163),\n",
       " (u'25', 163),\n",
       " (u'4.25', 160),\n",
       " (u'120', 156),\n",
       " (u'26', 153),\n",
       " (u'11.5', 152),\n",
       " (u'0.1', 152),\n",
       " (u'0.875', 148),\n",
       " (u'17.5', 145),\n",
       " (u'5.25', 145),\n",
       " (u'28', 143),\n",
       " (u'6.25', 142),\n",
       " (u'15.5', 137),\n",
       " (u'.75', 136),\n",
       " (u'5.75', 135),\n",
       " (u'32', 134),\n",
       " (u'23', 130),\n",
       " (u'8.25', 127),\n",
       " (u'14.5', 123),\n",
       " (u'8.75', 122),\n",
       " (u'.5', 122),\n",
       " (u'7.25', 119),\n",
       " (u'6.75', 117),\n",
       " (u'27', 117),\n",
       " (u'13.5', 116),\n",
       " (u'18.5', 115),\n",
       " (u'7.75', 114),\n",
       " (u'31', 114),\n",
       " (u'1.375', 110),\n",
       " (u'1.625', 110),\n",
       " (u'16.5', 108),\n",
       " (u'72', 108),\n",
       " (u'2.125', 105),\n",
       " (u'2.4', 105),\n",
       " (u'0.2', 103),\n",
       " (u'144', 101),\n",
       " (u'9.75', 101),\n",
       " (u'11.75', 98),\n",
       " (u'1.875', 94),\n",
       " (u'21.5', 93),\n",
       " (u'20.5', 90),\n",
       " (u'9.25', 89),\n",
       " (u'34', 88),\n",
       " (u'25.5', 85),\n",
       " (u'3.125', 84)]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size ranking\n",
    "Counter(df_pivoted_attributes['Product Width (in.)']).most_common(100)\n",
    "Counter(df_pivoted_attributes['Product Height (in.)']).most_common(100)\n",
    "Counter(df_pivoted_attributes['Product Depth (in.)']).most_common(100)\n",
    "Counter(df_pivoted_attributes['Product Weight (lb.)']).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(nan, 73326), (u'Indoor', 7527), (u'Indoor/Outdoor', 3904), (u'Outdoor', 1203), (u'Indoor,Outdoor', 256), (u'Indoor/Outdoor (Covered)', 47)]\n",
      "[(nan, 76733), (u'Commercial / Residential', 5011), (u'Residential', 4337), (u'Commercial', 182)]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "print Counter(df_pivoted_attributes['Indoor/Outdoor']).most_common(20)\n",
    "print Counter(df_pivoted_attributes['Commercial / Residential']).most_common(20)\n",
    "(u'Assembly Required', 5718, 3),\n",
    "(u'Finish', 4996, 667),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1, counter: Counter({1: 157528, 0: 80949, -1: 2283})\n",
      "n: 2, counter: Counter({1: 152028, 0: 63418, -1: 25314})\n",
      "n: 3, counter: Counter({1: 98216, -1: 93292, 0: 49252})\n",
      "n: 4, counter: Counter({-1: 169786, 1: 45286, 0: 25688})\n",
      "n: 5, counter: Counter({-1: 208878, 1: 19735, 0: 12147})\n",
      "n: 6, counter: Counter({-1: 228813, 1: 7584, 0: 4363})\n",
      "n: 7, counter: Counter({-1: 236371, 1: 2810, 0: 1579})\n",
      "n: 8, counter: Counter({-1: 239179, 1: 996, 0: 585})\n"
     ]
    }
   ],
   "source": [
    "df1['num_chars_in_search'] = num_chars_in_search(df1.search_term, remove_stopwords=True)\n",
    "\n",
    "df1['ratio_words_matched_search'] = ratio_words_matched(df1.search_term, df1.product_title, df1.index,\n",
    "                                                        remove_stopwords=True, lemma=True)\n",
    "\n",
    "df1['ratio_words_matched_title'] = ratio_words_matched(df1.search_term, df1.product_title, df1.index,\n",
    "                                                       remove_stopwords=True, lemma=True, denominator='product_title')\n",
    "\n",
    "df1['num_stopwords_in_search'] = num_stopwords_in_search(df1.search_term)\n",
    "\n",
    "df1['brand_matched'] = attribute_match('MFG Brand Name')\n",
    "df1['material_matched'] = attribute_match('Material')\n",
    "df1['Bullet01_matched'] = attribute_match('Bullet01')\n",
    "df1['Bullet02_matched'] = attribute_match('Bullet02')\n",
    "df1['Bullet03_matched'] = attribute_match('Bullet03')\n",
    "df1['Bullet04_matched'] = attribute_match('Bullet04')\n",
    "df1['Bullet05_matched'] = attribute_match('Bullet05')\n",
    "df1['Bullet06_matched'] = attribute_match('Bullet06')\n",
    "df1['Bullet07_matched'] = attribute_match('Bullet07')\n",
    "df1['Bullet08_matched'] = attribute_match('Bullet08')\n",
    "df1['Bullet09_matched'] = attribute_match('Bullet09')\n",
    "df1['Bullet10_matched'] = attribute_match('Bullet10')\n",
    "df1['color_family_matched'] = attribute_match('Color Family')\n",
    "df1['color_finish_matched'] = attribute_match('Color/Finish')\n",
    "\n",
    "df1['first_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 1)\n",
    "df1['second_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 2)\n",
    "df1['third_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 3)\n",
    "df1['fourth_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 4)\n",
    "df1['fifth_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 5)\n",
    "df1['sixth_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 6)\n",
    "df1['seventh_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 7)\n",
    "df1['eighth_word_matched'] = nth_word_matched(df1.search_term, df1.product_title, 8)\n",
    "\n",
    "df1['query_last_word_in_title'] = word_matched(df1.search_term, df1.product_title)\n",
    "df1['query_last_word_in_description'] = word_matched(df1.search_term, df1.product_description)\n",
    "\n",
    "# df1['num_tdidf_words'] = num_tdidf_words(df1.search_term)\n",
    "# sorted(Counter(df_pivoted_attributes['MFG Brand Name']).items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "tagger = PerceptronTagger()\n",
    "\n",
    "def pos_tag_count(searches):\n",
    "    word_pos = []\n",
    "    \n",
    "    count = 0    \n",
    "    for search_phrase in searches:\n",
    "        count += 1\n",
    "        if count % 50000 == 0:\n",
    "            print count \n",
    "            \n",
    "        word_pos.append(nltk.tag._pos_tag(search_phrase, None, tagger))\n",
    "    \n",
    "    return word_pos\n",
    "\n",
    "word_pos = pos_tag_count(df1.search_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_list = map(lambda word_list: [x[1] for x in word_list], word_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_all = []\n",
    "for pos in pos_list:\n",
    "    pos_all.extend(pos)\n",
    "\n",
    "pos_counts = Counter(pos_all)\n",
    "for pos, _ in pos_counts.iteritems():\n",
    "    df1['pos_' + str(pos)] = [x.count(pos) for x in pos_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_backup = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: n-gram matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up values for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_test_x(_df, features=None, feature_indices=None):\n",
    "    if features:\n",
    "        _df_train = _df[features][_df.dataset == 'train']\n",
    "        _df_test = _df[features][_df.dataset == 'test']\n",
    "    elif feature_indices:\n",
    "        _df = df.iloc[:, features_indices]\n",
    "        _df_train = _df[features][_df.dataset == 'train']\n",
    "        _df_test = _df[features][_df.dataset == 'test']\n",
    "    else:\n",
    "        _df_train = _df[_df.dataset == 'train']\n",
    "        _df_test = _df[_df.dataset == 'test']\n",
    "        \n",
    "        _df_train.drop(['dataset'], axis=1, inplace=True)\n",
    "        _df_test.drop(['dataset'], axis=1, inplace=True)\n",
    "        \n",
    "    return _df_train.values, _df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = [u'term_avg_score', u'ratio_words_matched_search',\n",
    "       u'ratio_words_matched_title', u'query_last_word_in_title',\n",
    "       u'product_titles_ns_3', u'product_titles_ns_1', u'product_titles_ns_4',\n",
    "       u'product_titles_ns_6', u'product_titles_ns_0', u'product_titles_ns_7',\n",
    "       u'product_titles_ns_9', u'product_titles_ns_5', u'product_titles_ns_2',\n",
    "       u'product_titles_ns_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# df1 = df_copy.copy()\n",
    "# df_copy = df1.copy()\n",
    "\n",
    "df1 = df1.drop(['product_uid', 'product_title', 'search_term', 'product_description'], axis=1)\n",
    "# x_train, x_test = get_train_test_x(df1, features = selected_features)\n",
    "x_train, x_test = get_train_test_x(df1)\n",
    "df1 = df1.drop(['dataset'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn import pipeline, grid_search\n",
    "\n",
    "def RMSE(y, y_pred):\n",
    "    return round(mean_squared_error(y, y_pred)**0.5, 3)\n",
    "\n",
    "def fmean_squared_error(ground_truth, predictions):\n",
    "    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n",
    "    return fmean_squared_error_\n",
    "RMSE_scorer = make_scorer(fmean_squared_error, greater_is_better=False)\n",
    "\n",
    "import sklearn.preprocessing as pp\n",
    "le = pp.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(random_state = 0, verbose = 0)\n",
    "param_grid = {'n_estimators':[30], 'max_features': [10], 'max_depth': [10]}\n",
    "model_rfr = grid_search.GridSearchCV(estimator = rfr, param_grid = param_grid, \n",
    "                                     cv = 2, verbose = 20, scoring=RMSE_scorer, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_model(_model, _x_train, _y_train):\n",
    "    _model.fit(_x_train, _y_train)\n",
    "\n",
    "    print(\"Best parameters found by grid search:\")\n",
    "    print(_model.best_params_)\n",
    "    print(\"Best CV score:\")\n",
    "    print(_model.best_score_)\n",
    "\n",
    "    return _model.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.450741688437\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.451271 -   6.4s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.450212 -   6.3s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.455590634323\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.454765 -   3.9s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.456417 -   3.8s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_optimized = run_model(model_rfr, x_train_copy, y_train_copy)\n",
    "# Full Feature Set\n",
    "# -0.449\n",
    "\n",
    "# {'max_features': 20, 'n_estimators': 800, 'max_depth': 20}\n",
    "# Best CV score:\n",
    "# -0.448834649641\n",
    "\n",
    "# 0.451271 before ensemble\n",
    "\n",
    "model_optimized = run_model(model_rfr, x_train, y_train)\n",
    "# Full Feature Set\n",
    "# -0.4521\n",
    "\n",
    "# {'max_features': 20, 'n_estimators': 800, 'max_depth': 20}\n",
    "# Best CV score:\n",
    "# -0.44682674871\n",
    "\n",
    "# 0.454765 before ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ith Ensemble Iteration: 1\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.455590634323\n",
      "ith Ensemble Iteration: 2[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.454765 -   3.6s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.456417 -   3.5s\n",
      "\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.428673640081\n",
      "ith Ensemble Iteration: 3[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.428474 -   3.6s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.428873 -   3.5s\n",
      "\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.401343060139\n",
      "ith Ensemble Iteration: 4[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.399475 -   3.8s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.403211 -   3.7s\n",
      "\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.375239497012\n",
      "ith Ensemble Iteration: 5[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.372036 -   3.9s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.378443 -   3.8s\n",
      "\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Best parameters found by grid search:\n",
      "{'max_features': 10, 'n_estimators': 30, 'max_depth': 10}\n",
      "Best CV score:\n",
      "-0.352779268327\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV] max_features=10, n_estimators=30, max_depth=10 ..................\n",
      "[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.347888 -   3.9s[CV]  max_features=10, n_estimators=30, max_depth=10, score=-0.357671 -   3.8s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "new_x_train = x_train\n",
    "\n",
    "ith_e = 0\n",
    "ensemble_iterations = 5\n",
    "while ith_e < ensemble_iterations:\n",
    "    curr_x_train = new_x_train\n",
    "    \n",
    "    ith_e += 1\n",
    "    print 'ith Ensemble Iteration: {}'.format(ith_e)\n",
    "    \n",
    "    model_optimized = run_model(model_rfr, curr_x_train, y_train)\n",
    "    output = model_optimized.predict(curr_x_train)\n",
    "    \n",
    "    new_x_train = np.zeros((curr_x_train.shape[0], curr_x_train.shape[1] + 1))\n",
    "    new_x_train[:,:-1] = curr_x_train\n",
    "    new_x_train[:,-1] = output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_optimized = run_model(model_optimized, new_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train all ensembles and see correlation and do hypertune weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classification instead and use majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "# from itertools import product\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# xgb = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.01, \n",
    "#                     objective='multi:softprob', subsample=0.5, \n",
    "#                     colsample_bytree=0.5, seed=0)\n",
    "\n",
    "# folds = 3\n",
    "# kfold = StratifiedKFold(y=y_train, n_folds=folds, shuffle=True, random_state=0)        \n",
    "\n",
    "# cum_score = 0\n",
    "# cum_score_train = 0\n",
    "\n",
    "# predictions_all = []\n",
    "# for k, (train, test) in enumerate(kfold):\n",
    "\n",
    "#     xgb.fit(x_train[train], y_train[train])\n",
    "\n",
    "#     output_train = xgb.predict(x_train[train])\n",
    "#     output = xgb.predict(x_train[test])\n",
    "        \n",
    "#     cum_score_train += RMSE(y_train[train], output_train) # not applied to classification yet\n",
    "#     cum_score += RMSE(y_train[test], output)\n",
    "#     predictions_all.append(output)\n",
    "\n",
    "# rmse_train = cum_score_train / float(folds)\n",
    "# rmse = cum_score / float(folds)\n",
    "\n",
    "# print 'Avg. RMSE (test): {}'.format(round(rmse,4))\n",
    "# print 'Avg. RMSE (train): {}'.format(round(rmse_train,4))\n",
    "\n",
    "# # param_grid = {'n_estimators': [50, 100], 'max_depth': [5, 10, 20], 'learning_rate': [0.01, 0.1]}\n",
    "# # model_xgb = grid_search.GridSearchCV(estimator = xgb, param_grid = param_grid, cv = 2, \n",
    "# #                                      verbose = 20, scoring=RMSE_scorer, n_jobs=-1)\n",
    "# # model_optimized_xgb = run_model(model_xgb, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "xgbr = XGBRegressor(seed=0)\n",
    "param_grid = {'objective':['reg:linear', 'reg:logistic'], \n",
    "              'n_estimators': [50], 'max_depth': [5], \n",
    "              'learning_rate': [0.01, 0.1]}\n",
    "\n",
    "model = grid_search.GridSearchCV(estimator = xgbr, param_grid = param_grid, cv = 2, \n",
    "                                 verbose = 20, scoring=RMSE_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(model.best_params_)\n",
    "print(\"Best CV score:\")\n",
    "print(model.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_copy = x_train \n",
    "y_train_copy = y_train\n",
    "\n",
    "# Best parameters found by grid search:\n",
    "# {'max_features': 5, 'n_estimators': 600, 'max_depth': 20}\n",
    "# Best CV score:\n",
    "# -0.447705321577"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from itertools import product\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "def run_kfold_process(clf, labels, partial_train=1):\n",
    "    \n",
    "    if partial_train < 1:\n",
    "        y_partial_train = y_train[:int(len(y_train) * partial_train)]\n",
    "    else:\n",
    "        y_partial_train = y_train\n",
    "        \n",
    "    folds = 3\n",
    "    kfold = StratifiedKFold(y=y_partial_train, n_folds=folds, shuffle=True, random_state=0)        \n",
    "    predictions_all = []\n",
    "    \n",
    "    cum_score = 0\n",
    "    cum_score_train = 0\n",
    "\n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        \n",
    "        clf.fit(x_train[train], labels[train])\n",
    "        \n",
    "        output_train = clf.predict(x_train[train])\n",
    "        output = clf.predict(x_train[test])\n",
    "            \n",
    "        cum_score_train += RMSE(y_train[train], output_train) # not applied to classification yet\n",
    "        cum_score += RMSE(y_train[test], output)\n",
    "\n",
    "        predictions_all.append(output)\n",
    "\n",
    "    rmse_train = cum_score_train / float(folds)\n",
    "    rmse = cum_score / float(folds)\n",
    "\n",
    "    print 'Avg. RMSE (test): {}'.format(round(rmse,4))\n",
    "    print 'Avg. RMSE (train): {}'.format(round(rmse_train,4))\n",
    "    \n",
    "    return predictions_all\n",
    "\n",
    "def train_clf(clf, partial_train=1):    \n",
    "\n",
    "    labels = y_train\n",
    "    predictions_all = run_kfold_process(clf, labels, partial_train=partial_train)\n",
    "        \n",
    "    return predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_n_estimators = [20, 30, 50, 80, 120, 200]\n",
    "param_max_depth = [10]\n",
    "param_max_features = [20]\n",
    "partial_factors = [1]\n",
    "\n",
    "for n_estimators, max_depth, max_features, partial_factor in itertools.product(\n",
    "    param_n_estimators, param_max_depth, param_max_features, partial_factors):\n",
    "    \n",
    "    print 'n_estimators: {}, max_depth: {}, max_features: {}, partial_train: {}'.format(\n",
    "        n_estimators, max_depth, max_features, partial_factor)\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                max_features=max_features, random_state=0)\n",
    "    \n",
    "    predictions_all = train_clf(rfr, partial_train=partial_factor)\n",
    "\n",
    "# 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "param_n_estimators = [30]\n",
    "partial_factors = [0.01, 0.1, 0.2, 0.5, 1]\n",
    "rfr = RandomForestRegressor(n_estimators=20, max_depth=10, max_features=20, random_state=0)\n",
    "\n",
    "for n_estimators, partial_factor in itertools.product(param_n_estimators, partial_factors):\n",
    "    print 'n_estimators: {}, partial_train: {}'.format(n_estimators, partial_factor)\n",
    "    br = BaggingRegressor(rfr, n_estimators=n_estimators, random_state=0)\n",
    "    predictions_all = train_clf(br, partial_train=partial_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import itertools\n",
    "\n",
    "param_n_estimators = [50]\n",
    "param_learning_rate = [0.1]\n",
    "partial_factors = [0.01, 0.1, 0.2, 0.5, 1]\n",
    "for n_estimators, learning_rate, partial_factor in itertools.product(param_n_estimators, \n",
    "                                                                     param_learning_rate, \n",
    "                                                                     partial_factors):\n",
    "    \n",
    "    print 'n_estimators: {}, learning_rate: {}, partial_factor: {}'.format(n_estimators, learning_rate, partial_factor)\n",
    "    abr = AdaBoostRegressor(rfr, n_estimators=n_estimators, learning_rate=learning_rate, random_state=0)\n",
    "    predictions_all = train_clf(abr, partial_train=partial_factor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# param_max_depth = [1, 5, 10]\n",
    "# param_n_estimators = [1, 5, 10, 20]\n",
    "# param_learning_rate = [0.001, 0.01, 0.1]\n",
    "param_max_depth = [10]\n",
    "param_max_features = [20]\n",
    "param_n_estimators = [30]\n",
    "param_learning_rate = [0.001, 0.01, 0.1, 1, 10]\n",
    "partial_factors = [1]\n",
    "for max_depth, n_estimators, learning_rate, partial_factor in itertools.product(param_max_depth,\n",
    "                                                                                param_max_features,\n",
    "                                                                                param_n_estimators, \n",
    "                                                                                param_learning_rate,\n",
    "                                                                                partial_factors):\n",
    "    \n",
    "    print 'max_depth: {}, max_features: {}, n_estimators: {}, learning_rate: {}, partial_factor: {}'.format(\n",
    "        max_depth, max_features, n_estimators, learning_rate, partial_factor)\n",
    "    gbr = GradientBoostingRegressor(max_depth=max_depth,\n",
    "                                    max_features=max_features,\n",
    "                                    n_estimators=n_estimators, \n",
    "                                    learning_rate=learning_rate, \n",
    "                                    random_state=0)\n",
    "    predictions_all = train_clf(gbr, partial_train=partial_factor)\n",
    "\n",
    "# 0.534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "\n",
    "param_n_estimators = [40, 80, 120]\n",
    "param_learning_rate = [0.05, 0.1, 0.25]\n",
    "params_max_depth = [10]\n",
    "# param_max_features = [20]\n",
    "# partial_factors = [0.1, 0.5, 1]\n",
    "partial_factors = [1]\n",
    "\n",
    "for n_estimators, learning_rate, max_depth, partial_factor in itertools.product(\n",
    "    param_n_estimators, param_learning_rate, params_max_depth, partial_factors):\n",
    "    \n",
    "    print 'n_estimators: {}, max_depth:{}, learning_rate: {}, partial_factor: {}'.format(\n",
    "        n_estimators, max_depth, learning_rate, partial_factor)\n",
    "    \n",
    "    xgbr = XGBRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, \n",
    "                        reg_alpha=1, seed=0)\n",
    "    \n",
    "    predictions_all = train_clf(xgbr, partial_train=partial_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print abr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15, 0.07, 0.04, 0.04, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Index([u'term_avg_score', u'ratio_words_matched_search',\n",
      "       u'ratio_words_matched_title', u'query_last_word_in_title',\n",
      "       u'product_titles_ns_3', u'product_titles_ns_1', u'product_titles_ns_4',\n",
      "       u'product_titles_ns_6', u'product_titles_ns_0', u'product_titles_ns_7',\n",
      "       u'product_titles_ns_9', u'product_titles_ns_5', u'product_titles_ns_2',\n",
      "       u'product_titles_ns_8', u'first_word_matched', u'num_chars_in_search',\n",
      "       u'search_term_ns_1', u'search_term_ns_6', u'search_term_ns_0',\n",
      "       u'search_term_ns_4', u'search_term_ns_3', u'search_term_ns_2',\n",
      "       u'search_term_ns_9', u'search_term_ns_8', u'search_term_ns_7',\n",
      "       u'search_term_ns_5', u'pos_NN', u'third_word_matched',\n",
      "       u'second_word_matched', u'pos_JJ', u'pos_NNP',\n",
      "       u'query_last_word_in_description', u'pos_DT', u'fourth_word_matched',\n",
      "       u'pos_VBP', u'pos_CD', u'pos_VBZ', u'pos_VB',\n",
      "       u'num_stopwords_in_search', u'Bullet01_matched', u'pos_VBD',\n",
      "       u'fifth_word_matched', u'pos_IN', u'Bullet02_matched',\n",
      "       u'Bullet03_matched', u'Bullet04_matched', u'pos_.', u'pos_NNS',\n",
      "       u'brand_matched', u'Bullet05_matched', u'pos_MD', u'Bullet06_matched',\n",
      "       u'pos_CC', u'Bullet07_matched', u'color_finish_matched',\n",
      "       u'Bullet08_matched', u'sixth_word_matched', u'pos_FW',\n",
      "       u'material_matched', u'Bullet09_matched', u'Bullet10_matched',\n",
      "       u'pos_RB', u'pos_$', u'color_family_matched', u'seventh_word_matched',\n",
      "       u'pos_PDT', u'pos_WRB', u'pos_RP', u'eighth_word_matched', u'pos_''',\n",
      "       u'pos_SYM', u'pos_:', u'pos_PRP', u'pos_LS', u'pos_POS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print map(lambda x: round(x, 2), sorted(model_optimized.feature_importances_)[::-1])\n",
    "print df1.columns[np.argsort(model_optimized.feature_importances_)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 22, 23, 47, 13, 11, 14, 16, 10, 17])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_best_k_features(k):\n",
    "    return np.argsort(model_optimized.feature_importances_)[::-1][:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d6e2490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b570950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predictions_all[0], 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'search_term_ns_0', u'search_term_ns_1', u'search_term_ns_2',\n",
      "       u'search_term_ns_3', u'search_term_ns_4', u'search_term_ns_5',\n",
      "       u'search_term_ns_6', u'search_term_ns_7', u'search_term_ns_8',\n",
      "       u'search_term_ns_9', u'product_titles_ns_0', u'product_titles_ns_1',\n",
      "       u'product_titles_ns_2', u'product_titles_ns_3', u'product_titles_ns_4',\n",
      "       u'product_titles_ns_5', u'product_titles_ns_6', u'product_titles_ns_7',\n",
      "       u'product_titles_ns_8', u'product_titles_ns_9', u'term_avg_score',\n",
      "       u'num_chars_in_search', u'ratio_words_matched_search',\n",
      "       u'ratio_words_matched_title', u'num_stopwords_in_search',\n",
      "       u'brand_matched', u'material_matched', u'Bullet01_matched',\n",
      "       u'Bullet02_matched', u'Bullet03_matched', u'Bullet04_matched',\n",
      "       u'Bullet05_matched', u'Bullet06_matched', u'Bullet07_matched',\n",
      "       u'Bullet08_matched', u'Bullet09_matched', u'Bullet10_matched',\n",
      "       u'color_family_matched', u'color_finish_matched', u'first_word_matched',\n",
      "       u'second_word_matched', u'third_word_matched', u'fourth_word_matched',\n",
      "       u'fifth_word_matched', u'sixth_word_matched', u'seventh_word_matched',\n",
      "       u'eighth_word_matched', u'query_last_word_in_title',\n",
      "       u'query_last_word_in_description', u'pos_FW', u'pos_''', u'pos_VBP',\n",
      "       u'pos_JJ', u'pos_VBZ', u'pos_DT', u'pos_RP', u'pos_$', u'pos_NN',\n",
      "       u'pos_VBD', u'pos_POS', u'pos_.', u'pos_LS', u'pos_RB', u'pos_:',\n",
      "       u'pos_NNS', u'pos_NNP', u'pos_VB', u'pos_WRB', u'pos_CC', u'pos_PDT',\n",
      "       u'pos_PRP', u'pos_CD', u'pos_IN', u'pos_MD', u'pos_SYM'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , -0.07, -0.06, ..., -0.03, -0.05, -0.01],\n",
       "       [-0.07,  1.  , -0.04, ...,  0.01, -0.  , -0.  ],\n",
       "       [-0.06, -0.04,  1.  , ..., -0.01,  0.  , -0.  ],\n",
       "       ..., \n",
       "       [-0.03,  0.01, -0.01, ...,  1.  , -0.02, -0.01],\n",
       "       [-0.05, -0.  ,  0.  , ..., -0.02,  1.  , -0.01],\n",
       "       [-0.01, -0.  , -0.  , ..., -0.01, -0.01,  1.  ]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df1.columns\n",
    "np.around(np.corrcoef(x_train, rowvar=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.29779612e-01   5.10047403e-02   2.45742289e-02   1.43206058e-02\n",
      "   1.19300068e-02   9.30124179e-03   6.82486093e-03   5.97816171e-03\n",
      "   4.71835344e-03   4.27539713e-03   3.56593050e-03   3.11976975e-03\n",
      "   2.89334897e-03   2.72864314e-03   2.22796209e-03   1.90911322e-03\n",
      "   1.86686927e-03   1.54889852e-03   1.50775185e-03   1.40597565e-03\n",
      "   1.18112823e-03   1.14722393e-03   1.02226056e-03   9.97150251e-04\n",
      "   9.59637525e-04   9.16359631e-04   8.33772968e-04   7.62886843e-04\n",
      "   5.73455674e-04   5.59401349e-04   4.59237096e-04   4.52774841e-04\n",
      "   4.35650109e-04   3.89293011e-04   3.40686760e-04   2.97326803e-04\n",
      "   2.77069552e-04   2.67203908e-04   2.63453565e-04   2.21053486e-04\n",
      "   2.16801190e-04   2.04661552e-04   1.50996396e-04   1.39749073e-04\n",
      "   1.30020468e-04   1.08257265e-04   1.05487419e-04   9.86445718e-05\n",
      "   8.61886631e-05   7.76049346e-05   7.36181615e-05   6.79767319e-05\n",
      "   6.70659302e-05   6.16046386e-05   5.69795650e-05   5.44557521e-05\n",
      "   4.72061815e-05   4.53877527e-05   4.26352876e-05   3.97236590e-05\n",
      "   3.68945767e-05   3.51465566e-05   3.11219149e-05   3.06545756e-05\n",
      "   2.70501087e-05   2.46049189e-05   2.03009384e-05   1.92032119e-05\n",
      "   1.62443937e-05   1.14493316e-05   1.06766015e-05   9.96334101e-06\n",
      "   8.58664391e-06   4.53951043e-06   8.60120258e-33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(x_train)\n",
    "print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "dot_data = StringIO() \n",
    "\n",
    "import graphviz\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "for i, _tree in enumerate(rfc.estimators_):\n",
    "    with open('figures/tree_' + str(i) + '.dot', 'w') as dotfile:\n",
    "        dot_data = StringIO() \n",
    "        tree.export_graphviz(_tree, out_file=dot_data)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "        \n",
    "#         graph = pydotplus.graph_from_dot_file('tree_0.dot') \n",
    "#         graph.write_pdf(\"tree.pdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_x_test = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_x_train = x_train\n",
    "\n",
    "# ith_e = 0\n",
    "# ensemble_iterations = 5\n",
    "# while ith_e < ensemble_iterations:\n",
    "#     curr_x_train = new_x_train\n",
    "    \n",
    "#     ith_e += 1\n",
    "#     print 'ith Ensemble Iteration: {}'.format(ith_e)\n",
    "    \n",
    "#     model_optimized = run_model(model_rfr, curr_x_train, y_train)\n",
    "#     output = model_optimized.predict(curr_x_train)\n",
    "    \n",
    "#     new_x_train = np.zeros((curr_x_train.shape[0], curr_x_train.shape[1] + 1))\n",
    "#     new_x_train[:,:-1] = curr_x_train\n",
    "#     new_x_train[:,-1] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 jobs       | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   8 | elapsed:  4.2min remaining: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:  5.0min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:  5.1min remaining:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:  5.9min remaining:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:  5.9min remaining:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   8 | elapsed:  6.8min remaining:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search:\n",
      "{'max_features': 25, 'n_estimators': 500, 'max_depth': 15}\n",
      "Best CV score:\n",
      "-0.445188510102\n",
      "[CV] max_features=15, n_estimators=500, max_depth=15 .................\n",
      "[CV] max_features=15, n_estimators=500, max_depth=15 .................\n",
      "[CV] max_features=25, n_estimators=500, max_depth=15 .................\n",
      "[CV] max_features=25, n_estimators=500, max_depth=15 .................\n",
      "[CV] max_features=15, n_estimators=500, max_depth=25 .................\n",
      "[CV] max_features=15, n_estimators=500, max_depth=25 .................\n",
      "[CV] max_features=25, n_estimators=500, max_depth=25 .................\n",
      "[CV] max_features=25, n_estimators=500, max_depth=25 .................\n",
      "[CV]  max_features=15, n_estimators=500, max_depth=15, score=-0.445801 - 4.2min[CV]  max_features=15, n_estimators=500, max_depth=15, score=-0.445393 - 4.1min[CV]  max_features=25, n_estimators=500, max_depth=15, score=-0.445797 - 5.9min[CV]  max_features=25, n_estimators=500, max_depth=15, score=-0.444580 - 5.9min[CV]  max_features=15, n_estimators=500, max_depth=25, score=-0.449310 - 5.0min[CV]  max_features=15, n_estimators=500, max_depth=25, score=-0.447515 - 5.0min[CV]  max_features=25, n_estimators=500, max_depth=25, score=-0.449696 - 6.7min[CV]  max_features=25, n_estimators=500, max_depth=25, score=-0.447351 - 6.7min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_x_train = x_train\n",
    "new_x_test = x_test\n",
    "\n",
    "rfr = RandomForestRegressor(random_state = 0, verbose = 0)\n",
    "param_grid = {'n_estimators':[500], 'max_features': [15,25], 'max_depth': [15,25]}\n",
    "model_rfr = grid_search.GridSearchCV(estimator = rfr, param_grid = param_grid, \n",
    "                                     cv = 2, verbose = 20, scoring=RMSE_scorer, n_jobs=-1)\n",
    "\n",
    "ith_e = 0\n",
    "ensemble_iterations = 1\n",
    "while ith_e < ensemble_iterations:\n",
    "    ith_e += 1\n",
    "    curr_x_train = new_x_train\n",
    "    curr_x_test = new_x_test\n",
    "    \n",
    "    model_optimized = run_model(model_rfr, curr_x_train, y_train)\n",
    "    output_train = model_optimized.predict(curr_x_train)\n",
    "\n",
    "    new_x_train = np.zeros((curr_x_train.shape[0], curr_x_train.shape[1]+1))\n",
    "    new_x_train[:,:-1] = curr_x_train\n",
    "    new_x_train[:,-1] = output_train\n",
    "\n",
    "    output_test = model_optimized.predict(curr_x_test)\n",
    "    new_x_test = np.zeros((curr_x_test.shape[0], curr_x_test.shape[1]+1))\n",
    "    new_x_test[:,:-1] = curr_x_test\n",
    "    new_x_test[:,-1] = output_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # rfr = RandomForestRegressor(max_depth=10, max_features=20, n_estimators=50, random_state=0)\n",
    "# model_optimized.fit(new_x_train, y_train)\n",
    "# preds = model_optimized.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "with open('results/results_rfr_ensemble.csv', 'wb') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['id', 'relevance'])\n",
    "    for id, pred in zip(df_test.id.values, preds):\n",
    "        csv_writer.writerow([id, pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import StratifiedKFold\n",
    "# from itertools import product\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# def run_kfold_process(clf, labels, predict_method, classification, partial_train=1):\n",
    "    \n",
    "#     if partial_train < 1:\n",
    "#         y_partial_train = y_train[:int(len(y_train) * partial_train)]\n",
    "#     else:\n",
    "#         y_partial_train = y_train\n",
    "        \n",
    "#     folds = 2\n",
    "#     kfold = StratifiedKFold(y=y_partial_train, n_folds=folds, shuffle=True, random_state=0)\n",
    "#     param_alpha = [0.1, 1, 10]\n",
    "#     history_rmse = [100]\n",
    "        \n",
    "#     predictions_all = []\n",
    "    \n",
    "#     if predict_method == 'clf':\n",
    "#         cum_score = 0\n",
    "#         cum_score_train = 0\n",
    "        \n",
    "#         for k, (train, test) in enumerate(kfold):\n",
    "#             clf.fit(x_train[train], labels[train])\n",
    "            \n",
    "#             if classification:\n",
    "#                 pass\n",
    "# #                 output = []\n",
    "# #                 predicted_probs = clf.predict_proba(x_test[test])\n",
    "                \n",
    "# #                 for predicted_prob in predicted_probs:\n",
    "# #                     output.append(le.inverse_transform(np.argsort(predicted_prob))[::-1][0])\n",
    "                    \n",
    "#             else:\n",
    "#                 output_train = clf.predict(x_test[train])\n",
    "#                 output = clf.predict(x_test[test])\n",
    "                \n",
    "#             print 'function_call k: {}, rmse: {}'.format(k, RMSE(y_train[test], output))\n",
    "                                           \n",
    "# #             rfr = RandomForestRegressor(max_depth=max_depth, max_features=max_features, n_estimators=30, random_state=0)\n",
    "# #             rfr.fit(x_train[train], y_train[train])\n",
    "# #             y_pred = rfr.predict(x_train[test])\n",
    "\n",
    "# #             print 'k:{}, rmse: {}'.format(k, RMSE(y_train[test], y_pred))\n",
    "        \n",
    "#             cum_score_train += RMSE(y_train[train], output_train) # not applied to classification yet\n",
    "#             cum_score += RMSE(y_train[test], output)\n",
    "            \n",
    "#             predictions = output\n",
    "#             predictions_all.append(predictions)\n",
    "                        \n",
    "#         rmse = cum_score / float(folds)\n",
    "#         rmse_train = cum_score_train / float(folds)\n",
    "# #         print 'k: {}, RMSE (test): {}, best: {}'.format(k, rmse, rmse <= min(history_rmse))\n",
    "# #         print 'k: {}, RMSE (train): {}, best: {}'.format(k, rmse_train, rmse <= min(history_rmse))\n",
    "#         history_rmse.append(rmse)\n",
    "    \n",
    "# #     elif predict_method == 'mean_clf':\n",
    "# #         param_weights = [0, 0.1, 0.2, 0.3]\n",
    "# #         for weight in param_weights:\n",
    "# #             cum_score = 0\n",
    "# #             for k, (train, test) in enumerate(kfold):\n",
    "                \n",
    "# #                 clf.fit(x_train[train], labels[train])\n",
    "# #                 output = clf.predict(x_test[test])\n",
    "                \n",
    "# #                 predictions = weight * output + u\n",
    "# #                 cum_score += RMSE(y_train[test], predictions)\n",
    "# #                 predictions_all.append(predictions)\n",
    "            \n",
    "# #             rmse = cum_score / float(folds)\n",
    "# #             print 'k: {}, weight: {}, RMSE: {}, best: {}'.format(k, weight, rmse, rmse <= min(history_rmse))\n",
    "# #             history_rmse.append(rmse)\n",
    "    \n",
    "#     return predictions_all\n",
    "\n",
    "# # predict_method: 'mean', 'clf', 'mean_clf' \n",
    "# # label_method: 'absolute', 'relative'\n",
    "# def train_clf(clf, features=None, predict_method = 'mean_clf', training_label_method = 'absolute', \n",
    "#               classification=False, partial_train=1):    \n",
    "    \n",
    "#     if predict_method == 'mean':\n",
    "        \n",
    "#         # no training required\n",
    "#         predictions = 0 * y_train + u\n",
    "#         print RMSE(y_train, predictions)\n",
    "    \n",
    "#     else:\n",
    "#         if classification:\n",
    "#             labels = le.fit_transform(y_train)\n",
    "#         else:\n",
    "#             if training_label_method == 'absolute':\n",
    "#                 labels = y_train\n",
    "#             elif training_label_method == 'relative':\n",
    "#                 labels = y_train - u\n",
    "        \n",
    "#         predictions_all = run_kfold_process(clf, labels, predict_method, classification, partial_train=partial_train)\n",
    "        \n",
    "#         return predictions_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
