{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint as pp\n",
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpldt\n",
    "import warnings\n",
    "import rank_metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_PATHS = {'train_users': 'train_users_2.csv',\n",
    "        'sessions': 'sessions.csv',\n",
    "        'countries': 'countries.csv',\n",
    "        'age_gender_bkts': 'age_gender_bkts.csv',\n",
    "        'test_users': 'test_users.csv'}\n",
    "\n",
    "DATASETS = {}\n",
    "\n",
    "# data = pd.DataFrame.from_csv(DATASET_PATHS['train_users'], header=0)\n",
    "DATASETS['training'] = pd.DataFrame.from_csv(DATASET_PATHS['train_users'], header=0)\n",
    "DATASETS['age_gender_bkts'] = pd.DataFrame.from_csv(DATASET_PATHS['age_gender_bkts'], header=0)\n",
    "DATASETS['countries'] = pd.DataFrame.from_csv(DATASET_PATHS['countries'], header=0)\n",
    "DATASETS['sessions'] = pd.DataFrame.from_csv(DATASET_PATHS['sessions'], header=0)\n",
    "DATASETS['testing'] = pd.DataFrame.from_csv(DATASET_PATHS['test_users'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = DATASETS['training'].copy()\n",
    "df_test = DATASETS['testing'].copy()\n",
    "df_age_gender_buckets = DATASETS['age_gender_bkts']\n",
    "\n",
    "df_test_x = df_test.copy()\n",
    "df_train_y = df_train['country_destination']\n",
    "df_train_x = df_train.drop('country_destination', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess sessions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_datasets(df, group_by_columns, pivot_by, column_length=None, custom_columns=None):\n",
    "    \n",
    "    df = df.reset_index().groupby(group_by_columns).sum().reset_index()\n",
    "    \n",
    "    if column_length:\n",
    "         columns, count = zip(*Counter(df[pivot_by]).most_common()[:column_length])\n",
    "    else:\n",
    "         columns, count = zip(*Counter(df[pivot_by]).most_common())\n",
    "        \n",
    "    columns = list(columns)\n",
    "    if custom_columns:\n",
    "        aggregated_df = df.pivot_table('secs_elapsed', 'user_id', pivot_by)[custom_columns] \n",
    "    else:\n",
    "        aggregated_df = df.pivot_table('secs_elapsed', 'user_id', pivot_by)[columns] \n",
    "    \n",
    "    aggregated_df.fillna(-1, inplace=True)\n",
    "    \n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_datasets_w_device(df, group_by_columns, pivot_by, column_length=None, custom_columns=None):\n",
    "    \n",
    "    group_by_columns = group_by_columns + ['device_type']\n",
    "    df = df.reset_index().groupby(group_by_columns + []).sum().reset_index()\n",
    "    \n",
    "    pivot_label = pivot_by + '_device_type'\n",
    "    df[pivot_label] = df[pivot_by] + '_' + df.device_type\n",
    "    \n",
    "    if column_length:\n",
    "        columns, count = zip(*Counter(df[pivot_label]).most_common()[:column_length])\n",
    "    else:\n",
    "        columns, count = zip(*Counter(df[pivot_label]).most_common())\n",
    "        \n",
    "    columns = list(columns)\n",
    "    if custom_columns:\n",
    "        aggregated_df = df.pivot_table('secs_elapsed', 'user_id', pivot_label)[custom_columns] \n",
    "    else:\n",
    "        aggregated_df = df.pivot_table('secs_elapsed', 'user_id', pivot_label)[columns] \n",
    "    \n",
    "    aggregated_df.fillna(-1, inplace=True)\n",
    "    \n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device_summary = group_datasets(DATASETS['sessions'].copy(),\n",
    "                                ['user_id','device_type'],\n",
    "                                'device_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_details_summary = group_datasets(DATASETS['sessions'].copy(), \n",
    "                                        ['user_id','action_detail'],\n",
    "                                        'action_detail', column_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions_generic_summary = group_datasets(DATASETS['sessions'].copy(), \n",
    "                                        ['user_id','action'],\n",
    "                                        'action', column_length=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions_type_columns = ['-unknown-', 'view', 'data', 'click', 'submit', 'message_post', \n",
    "                        'partner_callback', 'booking_request', 'booking_response']\n",
    "actions_type_summary = group_datasets(DATASETS['sessions'].copy(), \n",
    "                                        ['user_id','action_type'],\n",
    "                                        'action_type', custom_columns=actions_type_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>index_x</th>\n",
       "      <th>user_id</th>\n",
       "      <th>-unknown-_x</th>\n",
       "      <th>p3</th>\n",
       "      <th>header_userpic_x</th>\n",
       "      <th>view_search_results</th>\n",
       "      <th>wishlist_content_update</th>\n",
       "      <th>user_profile</th>\n",
       "      <th>change_trip_characteristics</th>\n",
       "      <th>...</th>\n",
       "      <th>Android Phone</th>\n",
       "      <th>iPad Tablet</th>\n",
       "      <th>Android App Unknown Phone/Tablet</th>\n",
       "      <th>Tablet</th>\n",
       "      <th>Linux Desktop</th>\n",
       "      <th>Chromebook</th>\n",
       "      <th>Windows Phone</th>\n",
       "      <th>Blackberry</th>\n",
       "      <th>iPodtouch</th>\n",
       "      <th>Opera Phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00023iyk9l</td>\n",
       "      <td>-1</td>\n",
       "      <td>60596</td>\n",
       "      <td>3198</td>\n",
       "      <td>54791</td>\n",
       "      <td>3515</td>\n",
       "      <td>-1</td>\n",
       "      <td>1447</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0010k6l0om</td>\n",
       "      <td>123033</td>\n",
       "      <td>229119</td>\n",
       "      <td>585</td>\n",
       "      <td>75951</td>\n",
       "      <td>135661</td>\n",
       "      <td>-1</td>\n",
       "      <td>20110</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>001wyh0pz8</td>\n",
       "      <td>22181</td>\n",
       "      <td>10639</td>\n",
       "      <td>-1</td>\n",
       "      <td>158796</td>\n",
       "      <td>-1</td>\n",
       "      <td>1510</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>282965</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0028jgx1x1</td>\n",
       "      <td>489</td>\n",
       "      <td>1027</td>\n",
       "      <td>-1</td>\n",
       "      <td>199802</td>\n",
       "      <td>-1</td>\n",
       "      <td>87089</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>002qnbzfs5</td>\n",
       "      <td>738169</td>\n",
       "      <td>56386</td>\n",
       "      <td>10954</td>\n",
       "      <td>493417</td>\n",
       "      <td>-1</td>\n",
       "      <td>125071</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  index_x     user_id  -unknown-_x      p3  header_userpic_x  \\\n",
       "0      0        0  00023iyk9l           -1   60596              3198   \n",
       "1      1        1  0010k6l0om       123033  229119               585   \n",
       "2      2        2  001wyh0pz8        22181   10639                -1   \n",
       "3      3        3  0028jgx1x1          489    1027                -1   \n",
       "4      4        4  002qnbzfs5       738169   56386             10954   \n",
       "\n",
       "   view_search_results  wishlist_content_update  user_profile  \\\n",
       "0                54791                     3515            -1   \n",
       "1                75951                   135661            -1   \n",
       "2               158796                       -1          1510   \n",
       "3               199802                       -1         87089   \n",
       "4               493417                       -1        125071   \n",
       "\n",
       "   change_trip_characteristics     ...       Android Phone  iPad Tablet  \\\n",
       "0                         1447     ...                  -1           -1   \n",
       "1                        20110     ...                  -1           -1   \n",
       "2                           -1     ...                  -1           -1   \n",
       "3                           -1     ...                  -1           -1   \n",
       "4                           -1     ...                  -1           -1   \n",
       "\n",
       "   Android App Unknown Phone/Tablet  Tablet  Linux Desktop  Chromebook  \\\n",
       "0                                -1      -1             -1          -1   \n",
       "1                                -1      -1             -1          -1   \n",
       "2                            282965      -1             -1          -1   \n",
       "3                                -1      -1             -1          -1   \n",
       "4                                -1      -1             -1          -1   \n",
       "\n",
       "   Windows Phone  Blackberry  iPodtouch  Opera Phone  \n",
       "0             -1          -1         -1           -1  \n",
       "1             -1          -1         -1           -1  \n",
       "2             -1          -1         -1           -1  \n",
       "3             -1          -1         -1           -1  \n",
       "4             -1          -1         -1           -1  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_summary = pd.merge(action_details_summary.reset_index(), actions_type_summary.reset_index(), on='user_id', how='outer')\n",
    "action_summary = pd.merge(action_summary.reset_index(), actions_generic_summary.reset_index(), on='user_id', how='outer')\n",
    "sessions_summary = pd.merge(action_summary.reset_index(), device_summary.reset_index(), on='user_id', how='outer')\n",
    "sessions_summary.fillna(-1, inplace=True)\n",
    "sessions_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing on the main dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = ['gender', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', \n",
    "                        'affiliate_provider', 'first_affiliate_tracked', 'signup_app', \n",
    "                        'first_device_type', 'first_browser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if feature frequencies are similar between training and testing set\n",
    "def print_feature_counter(df_train, df_test):\n",
    "    for f in categorical_features:\n",
    "        print 'feature: {}'.format(f)\n",
    "        print 'train set types: {}'.format(set(df_train[f]))\n",
    "        print 'test set types: {}'.format(set(df_test[f]))\n",
    "        \n",
    "        num_training_records = len(df_train)\n",
    "        num_testing_records = len(df_test)\n",
    "        \n",
    "        print 'train set types: {}'.format(Counter(df_train[f]))\n",
    "        print 'test set types: {} \\n'.format(Counter(df_test[f]))\n",
    "        \n",
    "# print_feature_counter(df_train_x, df_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Age Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = ['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records: 213451\n",
      "# of records w/ nan in attribute age: 87990\n",
      "% of records w/ nan in attribute age: 41.2%\n",
      "# of records: 62096\n",
      "# of records w/ nan in attribute age: 28876\n",
      "% of records w/ nan in attribute age: 46.5%\n"
     ]
    }
   ],
   "source": [
    "def how_many_nan(df, f):\n",
    "    print '# of records: {}'.format(len(df))\n",
    "    print '# of records w/ nan in attribute {}: {}'.format(\n",
    "        f, len(df[np.isnan(df[f])]))\n",
    "    print '% of records w/ nan in attribute {}: {}%'.format(\n",
    "        f, round(len(df[np.isnan(df[f])]) / float(len(df[f])) * 100, 1))\n",
    "    \n",
    "how_many_nan(df_train_x, 'age')\n",
    "how_many_nan(df_test_x, 'age') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_x['age'][(df_train_x['age'] <= 18) & (df_train_x['age'] >= 90)] = float('nan') \n",
    "df_test_x['age'][(df_test_x['age'] <= 18) & (df_test_x['age'] >= 90)] = float('nan')\n",
    "\n",
    "df_train_x['is_age_nan'] = 0\n",
    "df_train_x['is_age_nan'][df_train_x['age'].isnull()] = 1\n",
    "df_test_x['is_age_nan'] = 0\n",
    "df_test_x['is_age_nan'][df_test_x['age'].isnull()] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datetime_features = ['date_account_created', 'timestamp_first_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import math\n",
    "month_num2abbr = dict((k,v) for k,v in enumerate(calendar.month_abbr))\n",
    "\n",
    "def get_month_abbr(num):\n",
    "    if math.isnan(num):\n",
    "        return float('nan')\n",
    "    \n",
    "    return month_num2abbr[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import holidays\n",
    "import datetime\n",
    "day_of_week_mapper = {0:'M', 1:'T', 2:'W', 3:'R', 4:'F', 5:'S', 6:'U'}\n",
    "us_holidays = holidays.UnitedStates() \n",
    "for dataset in [df_train_x, df_test_x]:\n",
    "    for f in datetime_features:\n",
    "        if f == 'timestamp_first_active':\n",
    "            dataset.loc[:, f] = [datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:8])) \n",
    "                                 for x in dataset.loc[:, f]]\n",
    "        else:\n",
    "            dataset.loc[:, f] = pd.to_datetime(dataset.loc[:, f])\n",
    "        \n",
    "        # mapping month as categorical feature to keep seasonality\n",
    "        dataset[f + '_day_of_week'] = [day_of_week_mapper[x] for x in pd.DatetimeIndex(dataset[f]).dayofweek]\n",
    "        dataset[f + '_day'] = pd.DatetimeIndex(dataset[f]).day\n",
    "        dataset[f + '_month'] = map(get_month_abbr, pd.DatetimeIndex(dataset[f]).month)\n",
    "        dataset[f + '_year'] = pd.DatetimeIndex(dataset[f]).year - min(pd.DatetimeIndex(dataset[f]).year)\n",
    "        dataset[f + '_is_holiday'] = [x in us_holidays for x in pd.DatetimeIndex(dataset[f])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  only select most recent last year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_y = df_train_y[df_train_x.date_account_created_year == 4]\n",
    "df_train_x = df_train_x[df_train_x.date_account_created_year == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_drop_features = ['date_account_created', 'timestamp_first_active', 'date_first_booking']\n",
    "for dataset in [df_train_x, df_test_x]:\n",
    "    dataset.drop(to_drop_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge user account with sessions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# need to merge training and testing set to ensure \n",
    "# all possible categorical features are encoded\n",
    "\n",
    "df_train_x['source'] = 'train'\n",
    "df_test_x['source'] = 'test'\n",
    "_df = pd.concat([df_train_x, df_test_x])\n",
    "\n",
    "# merge main dataset with sessions action data\n",
    "_df = _df.reset_index()\n",
    "_df = _df.rename(columns = {'id':'user_id'})\n",
    "_df = pd.merge(_df, sessions_summary, how='left', on=['user_id'])\n",
    "_df.fillna(-1, inplace=True)\n",
    "_df = _df.set_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_df_encoded = pd.get_dummies(_df)\n",
    "_df_encoded.fillna(-1, inplace=True)\n",
    "\n",
    "df_train_x_encoded = _df_encoded[_df_encoded['source_train'] == 1]\n",
    "df_test_x_encoded = _df_encoded[_df_encoded['source_test'] == 1]\n",
    "    \n",
    "df_train_x_encoded.drop(['source_train', 'source_test'], axis=1, inplace=True)\n",
    "df_test_x_encoded.drop(['source_train', 'source_test'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe to values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "le = pp.LabelEncoder()\n",
    "train_y_encoded = le.fit_transform(df_train_y)\n",
    "\n",
    "x_train = df_train_x_encoded.values\n",
    "x_test = df_test_x_encoded.values\n",
    "y_train = train_y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom NDCG scorer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_ndcg(y_train, predicted_probs):\n",
    "    predicted_labels = []\n",
    "    for predicted_prob in predicted_probs:\n",
    "        predicted_labels.append(np.argsort(predicted_prob)[::-1][:5])\n",
    "\n",
    "    score = 0\n",
    "    for prediction, correct_label in zip(predicted_labels, y_train):\n",
    "        ranks = []\n",
    "        for pred_label in zip(prediction):\n",
    "            if pred_label == correct_label:\n",
    "                ranks.append(1)\n",
    "            else:\n",
    "                ranks.append(0)\n",
    "\n",
    "        score += rank_metrics.ndcg_at_k(ranks, 5, method=1)\n",
    "\n",
    "    return round(score / float(len(y_train)), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, Accuracy: 0.8572, max_depth: 6, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.75\n",
      "Fold: 1, Accuracy: 0.8563, max_depth: 6, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.75\n",
      "\n",
      "\n",
      "Fold: 0, Accuracy: 0.857, max_depth: 6, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.85\n",
      "Fold: 1, Accuracy: 0.8563, max_depth: 6, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.85\n",
      "\n",
      "\n",
      "Fold: 0, Accuracy: 0.8568, max_depth: 8, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.75\n",
      "Fold: 1, Accuracy: 0.8564, max_depth: 8, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.75\n",
      "\n",
      "\n",
      "Fold: 0, Accuracy: 0.8565, max_depth: 8, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.85\n",
      "Fold: 1, Accuracy: 0.8562, max_depth: 8, learning_rate: 0.2, n_estimators: 20, reg: 7.5, reg_lambda:1, subsample: 0.5, colsample_bytree: 0.85\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## XGBoost\n",
    "## with hyperparameter-tuning\n",
    "## w/ engineered features with all session variables\n",
    "## best set: alpha=0.2, n_estimators=50, score=0.8319\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from itertools import product\n",
    "import pdb\n",
    "\n",
    "kfold = StratifiedKFold(y=y_train, n_folds=2, shuffle=True, random_state=None)\n",
    "\n",
    "params_range = {}\n",
    "params_range['max_depth'] = [6, 8]\n",
    "params_range['learning_rate'] = [0.2] \n",
    "params_range['n_estimators'] = [20] \n",
    "params_range['reg'] = [7.5]\n",
    "params_range['reg_lambda'] = [1]\n",
    "params_range['subsample'] = [0.5]\n",
    "params_range['colsample_bytree'] = [0.75, 0.85]\n",
    "\n",
    "# grid search using k-holdout cross-validation\n",
    "for max_depth, alpha, n_estimators, reg, reg_lambda, subsample, colsample_bytree in product(params_range['max_depth'], params_range['learning_rate'], \n",
    "                                              params_range['n_estimators'], params_range['reg'], params_range['reg_lambda'], \n",
    "                                                   params_range['subsample'], params_range['colsample_bytree']): \n",
    "    \n",
    "    xgb = XGBClassifier(max_depth=max_depth, learning_rate=alpha, n_estimators=n_estimators,\n",
    "                        objective='multi:softprob', subsample=subsample, colsample_bytree=colsample_bytree, \n",
    "                        seed=0, reg_alpha=reg, reg_lambda=reg_lambda, silent=False) \n",
    "        \n",
    "    for k, (train, test) in enumerate(kfold):\n",
    "        xgb.fit(x_train[train], y_train[train])\n",
    "            \n",
    "        print 'Fold: {}, Accuracy: {}, max_depth: {}, learning_rate: {}, n_estimators: {}, reg: {}, reg_lambda:{}, subsample: {}, colsample_bytree: {}'.format(\n",
    "            k, score_ndcg(y_train[test], xgb.predict_proba(x_train[test])), \n",
    "            max_depth, alpha, n_estimators, reg, reg_lambda, subsample, colsample_bytree)\n",
    "\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train classifier with optimal parameters and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier(max_depth=8, learning_rate=0.2, n_estimators=25, \n",
    "                    objective='multi:softprob', subsample=0.5, \n",
    "                    colsample_bytree=0.5, seed=0, reg_alpha=7.5)\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "predicted_probs = xgb.predict_proba(x_test)\n",
    "predicted_labels = []\n",
    "for predicted_prob in predicted_probs:\n",
    "    predicted_labels.append(le.inverse_transform(np.argsort(predicted_prob))[::-1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "solution_set = defaultdict(list)\n",
    "\n",
    "predicted_labels_list = predicted_labels\n",
    "with open('results/predictions_xgb_2014.csv', 'wb') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(('id', 'country'))\n",
    "    for id, predicted_labels in zip(df_test_x_encoded.index.values, predicted_labels_list):\n",
    "        for predicted_label, rank in zip(predicted_labels, xrange(5)):      \n",
    "            solution_set[rank].append(predicted_label)\n",
    "            csv_writer.writerow((id, predicted_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
