{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Expedia Kaggle Competition: Goal is to use historical web session data (e.g. pageviews and booking data) to determine which hotel cluster the user booked. Hotel cluster is a numeric categorical attribute that is only meaningful to the team at Expedia. \n",
    "\n",
    "Due to the nature of the problem, a recommender system approach is used. Because the file sizes are quite large for to process locally, the data is sampled down to a smaller subset for training, cross-validation and testing purposes. To get the full results, a connection to Amazon Web Services is used to train and predict.\n",
    "\n",
    "The recommender system used different aggregated user data by various tuple keys, such as (e.g. (user_origin, sales_channel, session_month, destination_city) is considered a single key) and place all information that matches this key to a list. It then counts the top k elements from this list.\n",
    "\n",
    "Work on this project was stopped when a data leakage problem was discovered and announced in the Kaggle forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from math import log\n",
    "import entropy\n",
    "import csv\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv_by_sampling(fname, population_size, sample_size):\n",
    "    \"\"\" Sample stream of csv lines and returns Pandas object \n",
    "        Population size can be counted from command line wl -l %filename\n",
    "    \"\"\"\n",
    "    skip = sorted(random.sample(xrange(n), n-s))\n",
    "    return pd.read_csv('train.csv', skiprows=skip, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nan_analysis(_df):\n",
    "    \"\"\" shows nan values in dataframe \"\"\"\n",
    "    \n",
    "    # columns with missing values\n",
    "    columns_w_missing_values = _df.columns[_df.isnull().any()]\n",
    "    total = float(len(_df))\n",
    "    for col in columns_w_missing_values:\n",
    "        num_nans = sum(1 if x else 0 for x in _df[col].isnull())\n",
    "        print '# of nan values in column {0}: {1}, {2}'.format(col, \n",
    "                                                          num_nans,\n",
    "                                                          num_nans / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pct_top_k(labels, k, verbose=False):\n",
    "    \"\"\" returns percentnage dominated by top k elements in series \"\"\"\n",
    "    \n",
    "    labels_freq = Counter(labels)\n",
    "    total_freq = float(sum(labels_freq.values()))\n",
    "    total_uniques = len(labels)\n",
    "    \n",
    "    cum_k = cum_total = 0\n",
    "    tail_counter = 0    \n",
    "    \n",
    "    for n, (label, freq) in enumerate(sorted(labels_freq.items(), key=lambda x: x[1], reverse=True)):\n",
    "        if n < k:\n",
    "            cum_k += freq / total_freq\n",
    "            if verbose:\n",
    "                print '{0}:, marginal: {1}, cum: {2}'.format(label, freq / total_freq, cum_k)\n",
    "                \n",
    "    return cum_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tail_end_analysis(labels, tail_threshold, verbose=False):\n",
    "    \"\"\" outputs metrics on tail end (low-frequency counts) of series \"\"\"\n",
    "\n",
    "    labels_freq = Counter(labels)\n",
    "    total_freq = float(sum(labels_freq.values()))\n",
    "    total_uniques = len(labels_freq)\n",
    "    \n",
    "    cum_total = 0\n",
    "    tail_counter = 0    \n",
    "    \n",
    "    for n, (label, freq) in enumerate(sorted(labels_freq.items(), key=lambda x: x[1], reverse=True)):\n",
    "        if cum_total > tail_threshold:\n",
    "            tail_counter += 1\n",
    "        cum_total += freq / total_freq  \n",
    "    print 'There are {0} unique labels'.format(len(labels_freq))\n",
    "    print 'There are {0} elements beyond the {1}-threshold'.format(tail_counter, tail_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the User IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_id_training =  pd.read_csv('train.csv', usecols=['user_id'], header=0) \n",
    "user_id_testing =  pd.read_csv('test.csv', usecols=['user_id'], header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Training user ids: {}'.format(len(user_id_training['user_id']))\n",
    "print 'Testing user ids: {}'.format(len(user_id_testing['user_id']))\n",
    "print 'Training unique user ids: {}'.format(len(set(user_id_training['user_id'].unique())))\n",
    "print 'Testing unique user ids: {}'.format(len(set(user_id_testing['user_id'].unique())))\n",
    "print 'Common user ids: {}'.format(\n",
    "    len(set(user_id_training['user_id'].unique()) & set(user_id_testing['user_id'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_size = 2500000\n",
    "df_test = read_csv_by_sampling('test.csv', population_size, sample_size)\n",
    "df_test = pd.read_csv('test.csv', nrows=1000000, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = df_train['hotel_cluster'].values\n",
    "labels_freq = Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cum = pct_top_k(df_train['hotel_cluster'], 3, verbose=True)\n",
    "tail_end_analysis(df_train['hotel_cluster'], 0.9, verbose=True)\n",
    "entropy.shannon_entropy(df_train.site_name.values.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = df_train.columns\n",
    "for step_size in xrange(0,len(columns),5):\n",
    "    plt.figure();\n",
    "    _df = df_train[columns[step_size:step_size + 4]]\n",
    "    _df.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = ['site_name','posa_continent','user_location_country','user_location_region']\n",
    "df_train[['site_name','posa_continent']] = df_train[['site_name','posa_continent']].applymap(str)\n",
    "pd.get_dummies(df_train[['site_name','posa_continent']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentile_counter(counter_object, percentile=50):\n",
    "    yield_counts_per_userid = (x[1] for x in counter_object.items())\n",
    "    a = np.array([x for x in yield_counts_per_userid])\n",
    "    return np.percentile(a, percentile)\n",
    "\n",
    "print percentile_counter(Counter(df_train.user_id))\n",
    "print percentile_counter(Counter(df_train.user_id[df_train.is_booking==0]))\n",
    "print percentile_counter(Counter(df_train.user_id[df_train.is_booking==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_counter(counter_object, title):\n",
    "    yield_counts_per_userid = (x[1] for x in counter_object.items())\n",
    "    labels, values = zip(*counter_object.items())\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "    plt.bar(indexes, values, width)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def plot_counter_wrapper(generator, title):\n",
    "    id_counts_distribution = Counter(generator)\n",
    "    plot_counter(id_counts_distribution, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yield_counts_per_userid = (x[1] for x in Counter(df_train.user_id).items())\n",
    "plot_counter_wrapper(yield_counts_per_userid, '# of recorded events per user')\n",
    "\n",
    "yield_counts_per_userid = (x[1] for x in Counter(df_train.user_id[df_train.is_booking==0]).items())\n",
    "plot_counter_wrapper(yield_counts_per_userid, '# of non-bookings per user')\n",
    "\n",
    "yield_counts_per_userid = (x[1] for x in Counter(df_train.user_id[df_train.is_booking==1]).items())\n",
    "plot_counter_wrapper(yield_counts_per_userid, '# of bookings per user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model designs\n",
    "\n",
    "1. Time-invariant Hotel Cluster approach\n",
    "       Method ia. Count number of times a hotel cluster is selected (booking + non-bookings) by user\n",
    "       Method ib. Count number of times a hotel cluster is selected (booking-only) by user\n",
    "       Method ii. For each user, build a decision tree\n",
    "2. Keep track of past k events\n",
    "       for each booking event: use previous k non-booking events to predict y\n",
    "       (add recent-time-threshold for event to be considered in events. \n",
    "       e.g events 1, 2, 3 and all must be within past 6 months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Basic: Most Frequent hotel cluster of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_common_cluster_per_user = df_train[['user_id', 'hotel_cluster']].groupby(by=['user_id']).agg(\n",
    "    lambda x: list(zip(*Counter(x).most_common(5))[0]))\n",
    "most_common_cluster_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['hotel_cluster'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_freq_hotel_clusters = [x[0] for x in sorted(\n",
    "        Counter(df_train.hotel_cluster).items(), key=lambda x: x[1], reverse=True)[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_count = 0\n",
    "with open('output.csv', 'w') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow(['id','hotel_cluster'])\n",
    "    for nid in df_test['id']:\n",
    "        _count += 1\n",
    "        output_row = [nid]\n",
    "        output_row.append(' '.join(map(str, most_freq_hotel_clusters)))\n",
    "        csv_writer.writerow(output_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
